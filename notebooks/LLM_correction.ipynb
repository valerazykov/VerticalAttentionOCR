{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:56:05.270312Z",
     "iopub.status.busy": "2024-12-02T11:56:05.269313Z",
     "iopub.status.idle": "2024-12-02T11:56:05.565671Z",
     "shell.execute_reply": "2024-12-02T11:56:05.564725Z",
     "shell.execute_reply.started": "2024-12-02T11:56:05.270312Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = json.loads(requests.post(\n",
    "    'https://openai-proxy.tcsbank.ru/auth/v1/token',\n",
    "    json={\n",
    "        'username': f\"{os.getenv(\"GREENPLUM_USER\")}@tcsbank.ru\",\n",
    "        'password': os.getenv(\"GREENPLUM_PASSWORD\")\n",
    "    }).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {tokens['access_token']}\",  # Укажите реальный токен\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:56:14.698669Z",
     "iopub.status.busy": "2024-12-02T11:56:14.698669Z",
     "iopub.status.idle": "2024-12-02T11:56:14.721157Z",
     "shell.execute_reply": "2024-12-02T11:56:14.719156Z",
     "shell.execute_reply.started": "2024-12-02T11:56:14.698669Z"
    }
   },
   "outputs": [],
   "source": [
    "train_names = ['11', '15', '17', '17об', '18об', '19', '19об', '20', '20об', '21', '21об', '22', '23', '23об', '24', '24об', '25', '25об', '26', '26об', '27', '27об', '28', '28об', '29', '29об', '2об', '30об', '31', '31об', '32', '32об', '33', '33об', '34', '34об', '35', '35об', '36', '38', '38об', '39', '39об', '40', '40об', '41', '41об', '42', '42об', '43', '43об', '44', '45об', '46', '46об', '47', '47об', '48', '48об', '49', '49об', '50', '50об', '51', '51об', '52', '52об', '53', '53об', '54', '54об', '55', '55об', '56', '56об', '57', '57об', '58']\n",
    "val_names = ['58об', '59', '59об', '60', '60об']\n",
    "test_names = ['61', '75', '75об', '7об', '95']\n",
    "\n",
    "# train_names = ['11', '15', '17', '17об', '18', '18об', '19', '19об', '20', '20об', '21', '21об', '22', '22об', '23', '23об', '24', '24об', '25', '25об', '26', '26об', '27', '27об', '28', '28об', '29', '29об', '2об', '30', '30об', '31', '31об', '32', '32об', '33', '33об', '34', '34об', '35', '35об', '36', '38', '38об', '39', '39об', '40', '40об', '41', '41об', '42', '42об', '43', '43об', '44', '45об', '46', '46об', '47', '47об', '48', '48об', '49', '49об', '50', '50об', '51', '51об', '52', '52об', '53', '53об', '54', '54об', '55', '55об', '56', '56об', '57', '57об', '58', '58об']\n",
    "# val_names = ['59', '59об', '60', '60об']\n",
    "# #test_names = ['61', '75', '75об', '7об', '88об', '95']\n",
    "# test_names = ['61', '75', '75об', '7об', '95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:57:51.618838Z",
     "iopub.status.busy": "2024-12-02T11:57:51.617854Z",
     "iopub.status.idle": "2024-12-02T11:57:51.641178Z",
     "shell.execute_reply": "2024-12-02T11:57:51.639177Z",
     "shell.execute_reply.started": "2024-12-02T11:57:51.618838Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_human_and_model_pages(names, texts_path=\"../../Подстрочник/Дневник_С-К/438-1-219\", prefix=\"438-1-219 л\", skip_hashtag=True):\n",
    "    texts_path = Path(texts_path)\n",
    "    human_pages = []\n",
    "    model_pages = []\n",
    "\n",
    "    for name in names:\n",
    "        human_lines_filtered = []\n",
    "        model_lines_filtered = []\n",
    "        human_path = texts_path / \"Human_text\" / f\"{prefix}{name}.txt\"\n",
    "        model_path = texts_path / \"Model_text\" / f\"{prefix}{name}.txt\"\n",
    "        assert human_path.is_file()\n",
    "        assert model_path.is_file()\n",
    "        with open(human_path, \"r\", encoding=\"utf-8-sig\") as human_file:\n",
    "            human_lines = human_file.readlines()\n",
    "        with open(model_path, \"r\", encoding=\"utf-8-sig\") as model_file:\n",
    "            model_lines = model_file.readlines()\n",
    "\n",
    "        # Убираем пустую строку в конце\n",
    "        if human_lines[-1].strip() == \"\":\n",
    "            human_lines = human_lines[:-1]\n",
    "        if model_lines[-1].strip() == \"\":\n",
    "            model_lines = model_lines[:-1]\n",
    "\n",
    "        if len(human_lines) != len(model_lines) or len(model_lines) == 0:\n",
    "            print(f\"len(human_lines) != len(model_lines) or len(model_lines) == 0 for {name}\")\n",
    "            continue\n",
    "\n",
    "        for human_line, model_line in zip(human_lines, model_lines):\n",
    "            human_line = human_line.replace(\"\\u200b\", \"\").strip()\n",
    "            model_line = model_line.replace(\"\\u200b\", \"\").strip()\n",
    "            if skip_hashtag and \"#\" in human_line:\n",
    "                continue\n",
    "            if human_line[-1] == \"$\":\n",
    "                human_line = human_line[:-1]\n",
    "            if model_line[-1] == \"$\":\n",
    "                model_line = model_line[:-1]\n",
    "            human_lines_filtered.append(human_line)\n",
    "            model_lines_filtered.append(model_line)\n",
    "\n",
    "        human_pages.append(\"\\n\".join(human_lines_filtered))\n",
    "        model_pages.append(\"\\n\".join(model_lines_filtered))\n",
    "\n",
    "    return human_pages, model_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:57:31.891181Z",
     "iopub.status.busy": "2024-12-02T11:57:31.890179Z",
     "iopub.status.idle": "2024-12-02T11:57:31.900498Z",
     "shell.execute_reply": "2024-12-02T11:57:31.899487Z",
     "shell.execute_reply.started": "2024-12-02T11:57:31.891181Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_cer_from_pages(human_pages, model_pages, by_lines=True):\n",
    "    cer_sum = 0\n",
    "    n_chars_gt = 0\n",
    "    for human_page, model_page in zip(human_pages, model_pages, strict=True):\n",
    "        human_page = human_page.strip()\n",
    "        model_page = model_page.strip()\n",
    "        if by_lines:\n",
    "            for human_line, model_line in zip(human_page.split(\"\\n\"), model_page.split(\"\\n\"), strict=True):\n",
    "                cer_sum += editdistance.eval(human_line, model_line)\n",
    "                n_chars_gt += len(human_line)\n",
    "        else:\n",
    "            human_page = human_page.replace(\"\\n\", \" \")\n",
    "            model_page = model_page.replace(\"\\n\", \" \")\n",
    "            cer_sum += editdistance.eval(human_page, model_page)\n",
    "            n_chars_gt += len(human_page)\n",
    "    return cer_sum / n_chars_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:57:32.716676Z",
     "iopub.status.busy": "2024-12-02T11:57:32.715744Z",
     "iopub.status.idle": "2024-12-02T11:57:32.730677Z",
     "shell.execute_reply": "2024-12-02T11:57:32.729708Z",
     "shell.execute_reply.started": "2024-12-02T11:57:32.716676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "/var/folders/pp/0c5gvmy13ddcb_0yx8m9lfkw0000gq/T/ipykernel_24621/534092124.py:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "  str = re.sub('([\\[\\]{}/\\\\()\\\"\\'&+*=<>?.;:,!\\-—_€#%°])', r' \\1 ', str)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def format_string_for_wer(str):\n",
    "    str = re.sub('([\\[\\]{}/\\\\()\\\"\\'&+*=<>?.;:,!\\-—_€#%°])', r' \\1 ', str)\n",
    "    str = re.sub('([ \\n])+', \" \", str).strip()\n",
    "    return str\n",
    "\n",
    "\n",
    "def edit_wer_from_list(truth, pred):\n",
    "    edit = 0\n",
    "    for pred, gt in zip(pred, truth):\n",
    "        gt = format_string_for_wer(gt)\n",
    "        pred = format_string_for_wer(pred)\n",
    "        gt = gt.split(\" \")\n",
    "        pred = pred.split(\" \")\n",
    "        edit += editdistance.eval(gt, pred)\n",
    "    return edit\n",
    "\n",
    "\n",
    "def nb_words_from_list(list_gt):\n",
    "    len_ = 0\n",
    "    for gt in list_gt:\n",
    "        gt = format_string_for_wer(gt)\n",
    "        gt = gt.split(\" \")\n",
    "        len_ += len(gt)\n",
    "    return len_\n",
    "\n",
    "def wer_from_list_str(str_gt, str_pred):\n",
    "    len_ = 0\n",
    "    edit = 0\n",
    "    for pred, gt in zip(str_pred, str_gt):\n",
    "        gt = format_string_for_wer(gt)\n",
    "        pred = format_string_for_wer(pred)\n",
    "        gt = gt.split(\" \")\n",
    "        pred = pred.split(\" \")\n",
    "        edit += editdistance.eval(gt, pred)\n",
    "        len_ += len(gt)\n",
    "    cer = edit / len_\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:57:33.691390Z",
     "iopub.status.busy": "2024-12-02T11:57:33.691390Z",
     "iopub.status.idle": "2024-12-02T11:57:33.713391Z",
     "shell.execute_reply": "2024-12-02T11:57:33.711417Z",
     "shell.execute_reply.started": "2024-12-02T11:57:33.691390Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_wer_from_pages(human_pages, model_pages):\n",
    "    human_lines = []\n",
    "    model_lines = []\n",
    "    for human_page, model_page in zip(human_pages, model_pages, strict=True):\n",
    "        human_page = human_page.strip()\n",
    "        model_page = model_page.strip()\n",
    "        for human_line, model_line in zip(human_page.split(\"\\n\"), model_page.split(\"\\n\"), strict=True):\n",
    "            human_lines.append(human_line)\n",
    "            model_lines.append(model_line)\n",
    "    return wer_from_list_str(human_lines, model_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:57:56.171819Z",
     "iopub.status.busy": "2024-12-02T11:57:56.170804Z",
     "iopub.status.idle": "2024-12-02T11:57:56.204822Z",
     "shell.execute_reply": "2024-12-02T11:57:56.202802Z",
     "shell.execute_reply.started": "2024-12-02T11:57:56.171819Z"
    }
   },
   "outputs": [],
   "source": [
    "human_pages_val, model_pages_val = get_human_and_model_pages(val_names)\n",
    "human_pages_test, model_pages_test = get_human_and_model_pages(test_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:57:56.211865Z",
     "iopub.status.busy": "2024-12-02T11:57:56.210816Z",
     "iopub.status.idle": "2024-12-02T11:57:56.269261Z",
     "shell.execute_reply": "2024-12-02T11:57:56.267264Z",
     "shell.execute_reply.started": "2024-12-02T11:57:56.211865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28349584687612855"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_cer_from_pages(human_pages_val, model_pages_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22167200699097"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_cer_from_pages(human_pages_test, model_pages_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(human_pages, model_pages):\n",
    "    prompt = f\"\"\"Твоя задача - корректировать входной текст, исправляя в нем ошибки.\n",
    "Это текст, распознанный моделью компьютерного зрения с рукописей. Рукописи написаны на русском языке 19 века (также иногда присутствуют другие языки).\n",
    "Цель - получить максимально близкий к рукописи вариант расшифровки.\n",
    "Модель допускает много ошибок в распознавании символов.\n",
    "Исправляй только самые явные и понятные места. Если фрагмент текста сложно разобрать, то сохраняй его в том же виде, в котором и получил.\n",
    "Сохраняй имена собственные и числительные как есть. Сохраняй исходную последовательность слов.\"\"\"\n",
    "    examples = \"Примеры:\\n\"\n",
    "    for i, (human_page, model_page) in enumerate(zip(human_pages, model_pages, strict=True)):\n",
    "        for human_line, model_line in zip(human_page.split(\"\\n\"), model_page.split(\"\\n\"), strict=True):\n",
    "            human_line = human_line.strip()\n",
    "            model_line = model_line.strip()\n",
    "            examples += f\"{model_line} -> {human_line}\\n\"\n",
    "    return prompt + \"\\n\\n\" + examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'human_pages_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m make_system_prompt(\u001b[43mhuman_pages_val\u001b[49m, model_pages_val)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(system_prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'human_pages_val' is not defined"
     ]
    }
   ],
   "source": [
    "system_prompt = make_system_prompt(human_pages_val, model_pages_val)\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обрабатывем тестовые строки независимо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, access_token=tokens[\"access_token\"], system_prompt=system_prompt, temperature=0, model=\"chatgpt-4o-latest\", print_errors=True):\n",
    "    response = json.loads(\n",
    "        requests.post(\n",
    "            'https://openai-proxy.tcsbank.ru/public/v1/chat/completions', \n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {access_token}\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"x-proxy-mask-critical-data\": \"1\",\n",
    "                \"x-proxy-unmask-critical-data\": \"1\",\n",
    "            },\n",
    "            json={\n",
    "                \"model\": model,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\",  \"content\": question}\n",
    "                ],\n",
    "                \"temperature\": temperature,\n",
    "            },\n",
    "        ).text\n",
    "    )\n",
    "    if \"choices\" not in response:\n",
    "        if print_errors:\n",
    "            print(response)\n",
    "        return None\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мартъ. 3-го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной.\n"
     ]
    }
   ],
   "source": [
    "print(get_response(model_pages_test[3].split(\"\\n\")[0] + \" -> \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def get_correction(\n",
    "    model_pages,\n",
    "    **get_response_kwargs\n",
    "):\n",
    "    corrected_pages = []\n",
    "    for model_page in tqdm(model_pages):\n",
    "        corrected_lines = []\n",
    "        for model_line in tqdm(model_page.split(\"\\n\"), leave=False):\n",
    "            model_line = model_line.strip()\n",
    "            corrected_line = get_response(model_line + \" -> \", **get_response_kwargs)\n",
    "            if corrected_line is None:\n",
    "                time.sleep(10)\n",
    "                corrected_line = get_response(model_line + \" -> \", **get_response_kwargs)\n",
    "                if corrected_line is None:\n",
    "                    raise Exception(f\"Could not get response for {model_line}\")\n",
    "            corrected_lines.append(corrected_line)\n",
    "        corrected_pages.append(\"\\n\".join(corrected_lines))\n",
    "    return corrected_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:10<00:00, 110.12s/it]\n"
     ]
    }
   ],
   "source": [
    "corrected_pages_test = get_correction(model_pages_test, print_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "for human_page, corrected_page in zip(human_pages_test, corrected_pages_test, strict=True):\n",
    "    human_lines = human_page.strip().split(\"\\n\")\n",
    "    corrected_lines = corrected_page.strip().split(\"\\n\")\n",
    "    if len(human_lines) == len(corrected_lines):\n",
    "        print(\"ok\")\n",
    "    else:\n",
    "        print(\"not ok: \", end=\"\")\n",
    "        print(len(human_lines), len(corrected_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER до GPT:     0.2167\n",
      "CER после GPT:  0.2150\n"
     ]
    }
   ],
   "source": [
    "# отдельные строки как примеры\n",
    "print(f\"CER до GPT:    {calc_cer_from_pages(human_pages_test, model_pages_test, by_lines=False) : .4f}\")\n",
    "print(f\"CER после GPT: {calc_cer_from_pages(human_pages_test, corrected_pages_test, by_lines=False) : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER до GPT:     0.5991\n",
      "WER после GPT:  0.5178\n"
     ]
    }
   ],
   "source": [
    "# отдельные строки как примеры\n",
    "print(f\"WER до GPT:    {calc_wer_from_pages(human_pages_test, model_pages_test) : .4f}\")\n",
    "print(f\"WER после GPT: {calc_wer_from_pages(human_pages_test, corrected_pages_test) : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.2167\n",
      " 0.2636\n"
     ]
    }
   ],
   "source": [
    "# целые страницы как примеры\n",
    "print(f\"{calc_cer_from_pages(human_pages_test, model_pages_test, by_lines=False) : .4f}\")\n",
    "print(f\"{calc_cer_from_pages(human_pages_test, corrected_pages_test, by_lines=False) : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:   Рябикова\n",
      "ChatGPT: Рябикова\n",
      "Human:   Рябчикова\n",
      "\n",
      "Model:   Онь дсиля въ работникахъ и конца, и кроалъ что-т\n",
      "ChatGPT: Онъ дѣлялъ въ работникахъ и конца, и края что-то.\n",
      "Human:   Онъ де жилъ въ работникахъ у купца ; укралъ что-то\n",
      "\n",
      "Model:   ителъ удосилъ его палкой-по Голавѣ отъ чеи у не..\n",
      "ChatGPT: ителъ ударилъ его палкой по головѣ, отъ чего у не...\n",
      "Human:   и тотъ ударилъ его палкою по головѣ, отчаго у него\n",
      "\n",
      "Model:   и дѣлилаь удто бѣлая горянька. Обранясе къ Губер-\n",
      "ChatGPT: и дѣлилась, будто бѣлая горлинка. Обращаясь къ Губер-\n",
      "Human:   и сдѣлалась будто бѣлая горячка. Обратясь къ губер-\n",
      "\n",
      "Model:   натору. В - вросодъ въ, А ріес le . Смумаюсь.\n",
      "ChatGPT: натору. Въ – вопросъ въ А. Ріешѣніе. Сомневаюсь.\n",
      "Human:   натору: В – f! Prens-le, pince-le! – Слушаюсь.\n",
      "\n",
      "Model:   Болья никакилъ раторяженійи не было сцѣлано. Вороемъ\n",
      "ChatGPT: Большаго никакихъ распоряженій не было сдѣлано. Воробьемъ\n",
      "Human:   Болѣе никакихъ распоряженій и не было сдѣлано. Впрочемъ,\n",
      "\n",
      "Model:   « гасовые возватлѣтсь на преженія мѣста – ибо\n",
      "ChatGPT: «Гласные возвратились на прежнія мѣста – ибо\n",
      "Human:   и часовые возвратились на прежніе мѣста – ибо\n",
      "\n",
      "Model:   въ прочиньномъ слугаѣ и острожные остались бы беъ.1\n",
      "ChatGPT: въ прочайшемъ случаѣ и острожные остались бы безъ.\n",
      "Human:   въ противномъ случаѣ и острожные остались бы безъ\n",
      "\n",
      "Model:   всякагю кожаува. ie\n",
      "ChatGPT: всякаго кожуха.\n",
      "Human:   всякаго караула.\n",
      "\n",
      "Model:   .Вечеромъ литалъ піэссу – ядѣ чревынойно\n",
      "ChatGPT: Вечеромъ читалъ піэссу – ядѣ чрезвычайно\n",
      "Human:   Вечеромъ читалъ піэссу – Дядѣ чрезвычайно\n",
      "\n",
      "Model:   понравилась. – бекаеру также.\n",
      "ChatGPT: понравилась. – Беккеру также.\n",
      "Human:   понравилась – Беккеру также.\n",
      "\n",
      "Model:   10-г. утромъ выѣхалъ въ дѣекаеевское. Почвалъ в\n",
      "ChatGPT: 10-го. Утромъ выѣхалъ въ Дѣдкаевское. Почивалъ в...\n",
      "Human:   10-го утромъ выѣхалъ въ Алексеевское. Ночевалъ въ\n",
      "\n",
      "Model:   1856. Годъ май.\n",
      "ChatGPT: 1856. Годъ. Май.\n",
      "Human:   1856 годъ. Май\n",
      "\n",
      "Model:   д2. 23е – У 25. 26е. Въ Воскресенскомъ хлоно-\n",
      "ChatGPT: 23е. 25е. 26е. Въ Воскресенскомъ хлѣбо-\n",
      "Human:   21. 22. 23е. 24. 25. 26е. Въ Воскресенскомъ. Хлопо-\n",
      "\n",
      "Model:   25г. Пустилъ Заводъ. Вечеромъ прiѣхалъ Ѳедоръ изъ\n",
      "ChatGPT: 25-е. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ\n",
      "Human:   25е. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ\n",
      "\n",
      "Model:   Стемой - тамъ в сi подышается. Въ Воскресенскомъ\n",
      "ChatGPT: Стемной – тамъ въ сѣни подышается. Въ Воскресенскомъ\n",
      "Human:   Степной - тамъ всё подвигается. Въ Воскресенскомъ\n",
      "\n",
      "Model:   съ Феврался постутилъ и управлястъ Зерунъ.\n",
      "ChatGPT: Съ февраля поступилъ и управлялъ Зерунъ.\n",
      "Human:   съ февраля поступилъ и управляетъ Зерунъ.\n",
      "\n",
      "Model:   4тло идеть завольна хорошо. Садку сдѣлалъ по\n",
      "ChatGPT: Дѣло идётъ довольно хорошо. Садку сдѣлалъ по\n",
      "Human:   У него идетъ довольно хорошо. Садку сдѣлалъ по\n",
      "\n",
      "Model:   прачоій Сторонѣ ларка отъдома къ ренѣ. Около-\n",
      "ChatGPT: прачечной сторонѣ ларка отъ дома къ рѣкѣ. Около-\n",
      "Human:   правой сторонѣ парка отъ дома къ рѣкѣ. Около\n",
      "\n",
      "Model:   дома проводить тоссе. Ставили Кри мнѣ Туле\n",
      "ChatGPT: дома проводить время. Ставили крестъ мнѣ Туле.\n",
      "Human:   дома проводитъ шоссе. Ставили при мнѣ тум-\n",
      "\n",
      "Model:   бы оть дома къ Копонинѣ.\n",
      "ChatGPT: бы отъ дома къ Копонину.\n",
      "Human:   бы отъ дома къ конюшнѣ.\n",
      "\n",
      "Model:   i чано утру выѣхалъ въ Москву. Послалъ за\n",
      "ChatGPT: И рано утромъ выѣхалъ въ Москву. Послалъ за\n",
      "Human:   27е. По утру выѣхалъ въ Москву. Послалъ за\n",
      "\n",
      "Model:   Кавъ кимь который – явился съ предноженіемъ отъ\n",
      "ChatGPT: Кавъ кимъ, который явился съ предложеніемъ отъ\n",
      "Human:   Ковскимъ, который явился съ предложеніемъ отъ\n",
      "\n",
      "Model:   Ивача Пенелева о тирѣ. Сатомъ отѣъужанію\n",
      "ChatGPT: Ивача Пенелева о тирѣ. Съ этимъ отъѣзжанію\n",
      "Human:   Ивана Шепелева о мирѣ. Самсонъ отъѣзжаетъ\n",
      "\n",
      "Model:   съ Ревель. Кучилъ ему серебряныхъ вецій на 180.\n",
      "ChatGPT: съ Ревеля. Купилъ ему серебряныхъ вещей на 180.\n",
      "Human:   въ Ревель, купилъ ему серебряныхъ вещей на 180 р.\n",
      "\n",
      "Model:   с У Сазикова. Опедалъ Куботъ дни парвуки-\n",
      "ChatGPT: съ У Сазикова. Обедалъ. Кубокъ для церкви.\n",
      "Human:   сереб. у Садикова. Отдалъ кубокъ для нарѣзки\n",
      "\n",
      "Model:   накнися Самной лову. хадиить\n",
      "ChatGPT: наклонился со мной ловить. ходить\n",
      "Human:   надписи Самойлову. Надпись: \n",
      "\n",
      "Model:   3а снасніе почибавмихъ – Таланиц 1.\n",
      "ChatGPT: За счастіе погибающихъ – Талантія.\n",
      "Human:   За Спасеніе погибавшихъ – таланту В.В.\n",
      "\n",
      "Model:   Са-нойsло ва презнательные А. В. Сухово– Ко.\n",
      "ChatGPT: Самойслово признательные А. В. Сухово–Ко.\n",
      "Human:   Самойлова признательные А.В. Сухово-Ко-\n",
      "\n",
      "Model:   23е. Сборы, на Выксу. Проищаные съ Санелономъ.\n",
      "ChatGPT: 23-е. Сборы на Выксу. Прощанье съ Санелономъ.\n",
      "Human:   28е. Сборы на Выксу. Прощаніе съ Самсономъ.\n",
      "\n",
      "Model:   тодалъ ъ тудъ патаки но 180 к. сереб, и те р. сер.а\n",
      "ChatGPT: отдалъ туда пятаки на 180 к. сереб., и те р. сер.\n",
      "Human:   Продалъ 1 т. пудов патоки по 1.80 к. сер. и 1 т. р. сереб.\n",
      "\n",
      "Model:   вшсъ Рерстеру въ уплашу за апторать. Къ Саз\n",
      "ChatGPT: въсь Рейстеру въ уплату за аппаратъ. Къ Саз\n",
      "Human:   внесъ Ферстеру въ уплату за аппараты къ сахаръ-\n",
      "\n",
      "Model:   ному Lаводу. Вечеромь выкъхалъ на Выксиуъаи\n",
      "ChatGPT: нову Заводу. Вечеромъ выѣхалъ на Выксу.\n",
      "Human:   ному Заводу. Вечеромъ выѣхалъ на Выксу. \n",
      "\n",
      "Model:   24е.3ъ дорогъ. Хыюдно. простудался. Встрѣча въ\n",
      "ChatGPT: 24-е. Зъ дорогъ. Холодно. Простудился. Встрѣча въ\n",
      "Human:   29е. Въ дорогѣ. Холодно. Простудился. Встрѣча въ Вла-\n",
      "\n",
      "Model:   дувверѣ съ какимъ ополченскимъ о фидероме\n",
      "ChatGPT: доверіе съ какимъ ополченскимъ офицеромъ\n",
      "Human:   димірѣ съ какимъ ополченскимъ офицеромъ.\n",
      "\n",
      "Model:   Потулярность и всобщая, извѣсниеотъ Кренной\n",
      "ChatGPT: Популярность и всеобщая извѣстность отъ Кренной\n",
      "Human:   Популярность и всеобщая извѣстность Кречинского.\n",
      "\n",
      "Model:   Его ужа играли вовсй Россіи. Успѣхъ одинъ весен\n",
      "ChatGPT: Его уже играли во всей Россіи. Успѣхъ одинъ весен.\n",
      "Human:   Его уже играютъ во всей Россіи. Успѣхъ одинъ вездѣ.\n",
      "\n",
      "Model:   30е. въ 11 часовъ утра никѣмъ неождашный.\n",
      "ChatGPT: 30-е. Въ 11 часовъ утра никѣмъ неожидаемый.\n",
      "Human:   30е въ 11 часовъ утра никѣмъ неожиданный пріе-\n",
      "\n",
      "Model:   халъ на Выксу - отецъ былъ радъ онъ посторѣй\n",
      "ChatGPT: халъ на Выксу – отецъ былъ радъ, онъ постарѣл.\n",
      "Human:   халъ на Выксу - отецъ былъ радъ, онъ постарѣлъ\n",
      "\n",
      "Model:   иѣсколько потолстѣлъ и въ голось замѣжна нере-\n",
      "ChatGPT: нѣсколько потолстѣлъ, и въ голосѣ замѣтна нѣкая\n",
      "Human:   нѣсколько потолстѣлъ и въ голосѣ нѣсколько перемѣнился,\n",
      "\n",
      "Model:   нѣтъ твердости. На Выксѣ семра соловая,\n",
      "ChatGPT: нѣтъ твердости. На Выксѣ зима суровая,\n",
      "Human:   нѣтъ твердости. На Выксѣ сосѣди Соловые, сестра\n",
      "\n",
      "Model:   Сальяцъ. Пнк. Тепелилъ и в миховскій. Пиколой\n",
      "ChatGPT: Сальяцъ. Пнк. Тепелилъ и въ Миховскій. Пиколой.\n",
      "Human:   Сальясъ, Ник. Шепелевъ и Дмоховскій. Николай\n",
      "\n",
      "Model:   Гроть 1е. Рано утромъсъ гориныемъ выѣхалъ на сио.\n",
      "ChatGPT: Гротъ 1е. Рано утромъ съ Гориновымъ выѣхалъ на село.\n",
      "Human:   Іюнь. 1е. Рано утромъ съ Соринымъ выѣхалъ на Снаведь.\n",
      "\n",
      "Model:   Мвгупть. 3гo. Уѣхалъ въ Петербургъ ибо дѣло приняло дурной\n",
      "ChatGPT: Мартъ. 3-го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной\n",
      "Human:   Августъ 3го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной\n",
      "\n",
      "Model:   оборомъ въ Мни 1öen. Натало тяжекое время. Сѣрвсаколо-\n",
      "ChatGPT: оборомъ въ Мнѣ. Настало тяжкое время. Сѣрвсаколо-\n",
      "Human:   оборотъ въ Мин. Юст. Настало тяжелое время. Связь съ Голи-\n",
      "\n",
      "Model:   крѣнокъ. Ходилъ нѣсколько разъ греть на подку – и\n",
      "ChatGPT: крѣнокъ. Ходилъ нѣсколько разъ грѣться на подку – и\n",
      "Human:   крѣпокъ. Ходилъ нѣсколько разъ гресть на лодку - и\n",
      "\n",
      "Model:   купался въ шѣѣ до наловмы Августа.\n",
      "ChatGPT: купался въ рѣкѣ до половины Августа.\n",
      "Human:   купался въ Невѣ съ половины августа.\n",
      "\n",
      "Model:   Сенслябрь. Въ Петербургѣ. Подалъ запику М. Фв о\n",
      "ChatGPT: Сентябрь. Въ Петербургѣ. Подалъ записку М. Ф. о\n",
      "Human:   Сентябрь. Въ Петербургѣ. Подалъ записку м. ф-ов о\n",
      "\n",
      "Model:   предкриятіи въ 8ж. Россіи. Отаровили на Выксу и\n",
      "ChatGPT: предпріятіи въ Юж. Россіи. Остановились на Выксѣ и\n",
      "Human:   предпрiятiи въ Юж. Россiи. Отправился на Выксу и\n",
      "\n",
      "Model:   заклочилъ у словсе съ vнк. Иется. Прiѣхалъ обранна\n",
      "ChatGPT: заключилъ у словесъ съ Инкомъ. Еду. Пріѣхалъ обратно.\n",
      "Human:   заключилъ условие с Ник. Шепел. Прiѣхалъ обратно\n",
      "\n",
      "Model:   въ Петербургъ. 13ге. Нояюря. Сововые сыня и мамаковъ\n",
      "ChatGPT: въ Петербургъ. 13-е. Ноября. Совѣщаніе съ сыномъ и Мамоновым.\n",
      "Human:   въ Петербургъ 13го ноября. Соловые. Соня и Маменька въ\n",
      "\n",
      "Model:   Петербургѣ. Жиднь въ свстицѣ Демдова. Постояно\n",
      "ChatGPT: Петербургѣ. Жизнь въ свѣтѣ Демидова. Постоянно\n",
      "Human:   Петербургѣ. Жизнь въ гостиницѣ Демидова. Постановилъ\n",
      "\n",
      "Model:   ходилъ въ Дерошу но устрамъ. Окочилъ 2оп и 3 м Ѳекетъ.\n",
      "ChatGPT: Ходилъ въ Дерошу на утреню. Окончилъ 2-й часъ и 3-й мѣсяцъ Фекетъ.\n",
      "Human:   ходить къ Депону по утрамъ. Окончилъ 2ой и 3iй актъ. \n",
      "\n",
      "Model:   Дѣло въ Гомуд. Солѣтѣ. вбр Торги на вичновые\n",
      "ChatGPT: Дѣло въ Гомудѣ. Совѣтѣ. Въ Торги на вѣщевые\n",
      "Human:   Дѣло въ Госуд. Советѣ. Декабрь Торги на винтовые\n",
      "\n",
      "Model:   Корабни. Конывъ и Шульчмъ въ Петербургѣ. Декабрь.\n",
      "ChatGPT: Корабли. Конывъ и Шульцъ въ Петербургѣ. Декабрь.\n",
      "Human:   корабли. Копьевъ и Шульгинъ въ Петербургѣ. Декабрь. \n",
      "\n",
      "Model:   возвранинся въ Москву.\n",
      "ChatGPT: возвратился въ Москву.\n",
      "Human:   Возвратился въ Москву. \n",
      "\n",
      "Model:   12f4. Годъ. Новый годъ нажелзной дорогѣ. Былъ въ Доскре-\n",
      "ChatGPT: 1854. Годъ. Новый годъ на желѣзной дорогѣ. Былъ въ Москве.\n",
      "Human:   1854 годъ. Новый годъ на желѣзной дорогѣ. Былъ в Воскре-\n",
      "\n",
      "Model:   сискомъ. 15 чеила выѣхалъ на Выксу. Амнлte Гол.\n",
      "ChatGPT: спискомъ. 15 числа выѣхалъ на Выксу. Аминте Гол.\n",
      "Human:   сенскомъ. 15 числа выѣхал на Выксу. Anette Гол. \n",
      "\n",
      "Model:   Ныеса читалась въ уепѣхомъ. Въ оРевранѣ,\n",
      "ChatGPT: Нъеса читалась съ успѣхомъ. Въ Ореврані,\n",
      "Human:   Пьесса читалась съ успехомъ. Въ февралѣ\n",
      "\n",
      "Model:   должъ былъ ѣхатъ въ Москку по полоду насавшается\n",
      "ChatGPT: долженъ былъ ѣхать въ Москву по поводу насущается\n",
      "Human:   долженъ былъ выѣхать въ Москву по поводу начавшагося\n",
      "\n",
      "Model:   Слѣхмвся. Вздилъ на нѣскольоо дней въ Пентербургъ.\n",
      "ChatGPT: Слѣхался. Ъздилъ на нѣсколько дней въ Петербургъ.\n",
      "Human:   слѣдствiя. Ѣздилъ на нѣсколько дней в Петербургъ.\n",
      "\n",
      "Model:   Нталъ охоимисьихъ вещю ченобы охотиться.\n",
      "ChatGPT: Наталъ охотничьихъ вещей, чтобы охотиться.\n",
      "Human:   Покупалъ охотничьихѣ вещей, чтобы охотиться. \n",
      "\n",
      "Model:   2гo мадна на первой не дѣли воротилси въ Москву.\n",
      "ChatGPT: 2-го марта на первой недѣле воротился въ Москву.\n",
      "Human:   1гo марта на первой недѣлѣ воротился въ Москву. \n",
      "\n",
      "Model:   для пріiема Дамь. Онъ пріѣхали поздно. Обѣдали въ 6-м часу был\n",
      "ChatGPT: для пріема Дамъ. Онъ пріѣхалъ поздно. Обѣдали въ 6-м часу. Был...\n",
      "Human:   для пріема дамъ. Онѣ пріѣхали поздно. Обѣдали въ 6мъ часу – было\n",
      "\n",
      "Model:   довольна весел. – Я очно вечеко игралъ въ карты\n",
      "ChatGPT: довольно весел. – Я очно вечеромъ игралъ въ карты.\n",
      "Human:   довольно весело. – Я очень весело игралъ въ карты. –\n",
      "\n",
      "Model:   нѣлтъ яЯ отправичъ Семна нъ В Туму Запродать будущаго Cахора\n",
      "ChatGPT: нѣлтъ я. Я отправилъ Семена въ Тулу запродать будущаго сахара.\n",
      "Human:   нѣтъ. Я отправилъ Семена Ив. въ Тулу запродать будущаго сахара.\n",
      "\n",
      "Model:   228-е Лmmи яяшалъ рао Споляничалъ. Рапимывалъ и отпровилъ Выю-\n",
      "ChatGPT: 228-е. Лѣтомъ я езжалъ рано. Сполянничалъ, размышлялъ и отправилъ въ Выю-\n",
      "Human:   28е. Всталъ рано. Столярничалъ. Разсчитывалъ и отправилъ Вык-\n",
      "\n",
      "Model:   Симкилъ 18 человѣсъ. Но обратныхъ пододовъ ратробовалъ изъ Москвы\n",
      "ChatGPT: Симкилъ 18 человѣкъ. Но обратныхъ подводъ потребовалъ изъ Москвы.\n",
      "Human:   сунскихъ 18 человѣкъ. На обратныхъ подводахъ затребовалъ изъ Москвы\n",
      "\n",
      "Model:   Либили, картинъ, броизу. Естя прѣ пиводь буду жить 7 Россіи – накъ\n",
      "ChatGPT: Либрии, картинъ, бронзу. Если при выводѣ буду жить въ Россіи – такъ\n",
      "Human:   мебель, картины, бронзу. Если я гдѣ-нибудь буду жить въ Россіи – такъ\n",
      "\n",
      "Model:   это сдѣся – въ кобылимкѣ..\n",
      "ChatGPT: это здѣсь – въ Кобылинкѣ.\n",
      "Human:   это здѣсь – въ Кобылинкѣ.\n",
      "\n",
      "Model:   Замѣчательныой раскаръ О помещикѣ Малиновскомъ убинноъ се\n",
      "ChatGPT: Замѣчательной разсказъ о помещикѣ Малиновскомъ, убившемъ се-\n",
      "Human:   Замѣчательный расказъ о помѣщикѣ Маниловскому, убитомъ его\n",
      "\n",
      "Model:   костьяноми. Какъ Замѣнно это было Сильной странно.\n",
      "ChatGPT: костьяными. Какъ замѣтно это было сильно странно.\n",
      "Human:   крестьянами. Какъ замѣтно это была сильная, страшно\n",
      "\n",
      "Model:   4.онъ довева Крестьямъ до большаго блаю состоянія и богати.\n",
      "ChatGPT: 4. Онъ довелъ крестьянъ до большаго благосостоянія и богатства.\n",
      "Human:   онъ довелъ крестьянъ до большого благосостоянія и богат-\n",
      "\n",
      "Model:   1ства, получилъ имѣніе разоренное– и кресетьяхъ противишотія –\n",
      "ChatGPT: имѣніе разоренное – и крестьянахъ противящихся –\n",
      "Human:   ства, получивъ имѣніе разоренное и крестьянъ прожившихся.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_page, corrected_page, human_page in zip(model_pages_test, corrected_pages_test, human_pages_test, strict=True):\n",
    "    for model_line, corrected_line, human_line in zip(model_page.split(\"\\n\"), corrected_page.split(\"\\n\"), human_page.split(\"\\n\"), strict=True):\n",
    "        print(f\"Model:   {model_line}\")\n",
    "        print(f\"ChatGPT: {corrected_line}\")\n",
    "        print(f\"Human:   {human_line}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# with open(\"corrected_pages_test.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(corrected_pages_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T11:59:04.594077Z",
     "iopub.status.busy": "2024-12-02T11:59:04.594077Z",
     "iopub.status.idle": "2024-12-02T11:59:04.617394Z",
     "shell.execute_reply": "2024-12-02T11:59:04.615263Z",
     "shell.execute_reply.started": "2024-12-02T11:59:04.594077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Рябикова\\nОнъ дѣлялъ въ работникахъ и конца, и края что-то.\\nителъ ударилъ его палкой по головѣ, отъ чего у не...\\nи дѣлилась, будто бѣлая горлинка. Обращаясь къ Губер-\\nнатору. Въ – вопросъ въ А. Ріешѣніе. Сомневаюсь.\\nБольшаго никакихъ распоряженій не было сдѣлано. Воробьемъ\\n«Гласные возвратились на прежнія мѣста – ибо\\nвъ прочайшемъ случаѣ и острожные остались бы безъ.\\nвсякаго кожуха.\\nВечеромъ читалъ піэссу – ядѣ чрезвычайно\\nпонравилась. – Беккеру также.\\n10-го. Утромъ выѣхалъ въ Дѣдкаевское. Почивалъ в...',\n",
       " '1856. Годъ. Май.\\n23е. 25е. 26е. Въ Воскресенскомъ хлѣбо-\\n25-е. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ\\nСтемной – тамъ въ сѣни подышается. Въ Воскресенскомъ\\nСъ февраля поступилъ и управлялъ Зерунъ.\\nДѣло идётъ довольно хорошо. Садку сдѣлалъ по\\nпрачечной сторонѣ ларка отъ дома къ рѣкѣ. Около-\\nдома проводить время. Ставили крестъ мнѣ Туле.\\nбы отъ дома къ Копонину.\\nИ рано утромъ выѣхалъ въ Москву. Послалъ за\\nКавъ кимъ, который явился съ предложеніемъ отъ\\nИвача Пенелева о тирѣ. Съ этимъ отъѣзжанію\\nсъ Ревеля. Купилъ ему серебряныхъ вещей на 180.\\nсъ У Сазикова. Обедалъ. Кубокъ для церкви.\\nнаклонился со мной ловить. ходить\\nЗа счастіе погибающихъ – Талантія.\\nСамойслово признательные А. В. Сухово–Ко.\\n23-е. Сборы на Выксу. Прощанье съ Санелономъ.\\nотдалъ туда пятаки на 180 к. сереб., и те р. сер.\\nвъсь Рейстеру въ уплату за аппаратъ. Къ Саз\\nнову Заводу. Вечеромъ выѣхалъ на Выксу.',\n",
       " '24-е. Зъ дорогъ. Холодно. Простудился. Встрѣча въ\\nдоверіе съ какимъ ополченскимъ офицеромъ\\nПопулярность и всеобщая извѣстность отъ Кренной\\nЕго уже играли во всей Россіи. Успѣхъ одинъ весен.\\n30-е. Въ 11 часовъ утра никѣмъ неожидаемый.\\nхалъ на Выксу – отецъ былъ радъ, онъ постарѣл.\\nнѣсколько потолстѣлъ, и въ голосѣ замѣтна нѣкая\\nнѣтъ твердости. На Выксѣ зима суровая,\\nСальяцъ. Пнк. Тепелилъ и въ Миховскій. Пиколой.\\nГротъ 1е. Рано утромъ съ Гориновымъ выѣхалъ на село.',\n",
       " 'Мартъ. 3-го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной\\nоборомъ въ Мнѣ. Настало тяжкое время. Сѣрвсаколо-\\nкрѣнокъ. Ходилъ нѣсколько разъ грѣться на подку – и\\nкупался въ рѣкѣ до половины Августа.\\nСентябрь. Въ Петербургѣ. Подалъ записку М. Ф. о\\nпредпріятіи въ Юж. Россіи. Остановились на Выксѣ и\\nзаключилъ у словесъ съ Инкомъ. Еду. Пріѣхалъ обратно.\\nвъ Петербургъ. 13-е. Ноября. Совѣщаніе съ сыномъ и Мамоновым.\\nПетербургѣ. Жизнь въ свѣтѣ Демидова. Постоянно\\nХодилъ въ Дерошу на утреню. Окончилъ 2-й часъ и 3-й мѣсяцъ Фекетъ.\\nДѣло въ Гомудѣ. Совѣтѣ. Въ Торги на вѣщевые\\nКорабли. Конывъ и Шульцъ въ Петербургѣ. Декабрь.\\nвозвратился въ Москву.\\n1854. Годъ. Новый годъ на желѣзной дорогѣ. Былъ въ Москве.\\nспискомъ. 15 числа выѣхалъ на Выксу. Аминте Гол.\\nНъеса читалась съ успѣхомъ. Въ Ореврані,\\nдолженъ былъ ѣхать въ Москву по поводу насущается\\nСлѣхался. Ъздилъ на нѣсколько дней въ Петербургъ.\\nНаталъ охотничьихъ вещей, чтобы охотиться.\\n2-го марта на первой недѣле воротился въ Москву.',\n",
       " 'для пріема Дамъ. Онъ пріѣхалъ поздно. Обѣдали въ 6-м часу. Был...\\nдовольно весел. – Я очно вечеромъ игралъ въ карты.\\nнѣлтъ я. Я отправилъ Семена въ Тулу запродать будущаго сахара.\\n228-е. Лѣтомъ я езжалъ рано. Сполянничалъ, размышлялъ и отправилъ въ Выю-\\nСимкилъ 18 человѣкъ. Но обратныхъ подводъ потребовалъ изъ Москвы.\\nЛибрии, картинъ, бронзу. Если при выводѣ буду жить въ Россіи – такъ\\nэто здѣсь – въ Кобылинкѣ.\\nЗамѣчательной разсказъ о помещикѣ Малиновскомъ, убившемъ се-\\nкостьяными. Какъ замѣтно это было сильно странно.\\n4. Онъ довелъ крестьянъ до большаго благосостоянія и богатства.\\nимѣніе разоренное – и крестьянахъ противящихся –']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pickle\n",
    "\n",
    "\n",
    "# with open(\"corrected_pages_test.pkl\", \"rb\") as f:\n",
    "#     loaded = pickle.load(f)\n",
    "\n",
    "# loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## При коррекции тестовых строк учитывеем историю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_v2(\n",
    "    question,\n",
    "    conversation_history=None,\n",
    "    access_token=tokens[\"access_token\"],\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0,\n",
    "    model=\"chatgpt-4o-latest\",\n",
    "    print_errors=True\n",
    "):\n",
    "    # Если история разговора отсутствует, инициализируем ее с системным сообщением\n",
    "    if conversation_history is None:\n",
    "        conversation_history = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    # Добавляем вопрос пользователя в историю разговора\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    response = requests.post(\n",
    "        'https://openai-proxy.tcsbank.ru/public/v1/chat/completions', \n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {access_token}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"x-proxy-mask-critical-data\": \"1\",\n",
    "            \"x-proxy-unmask-critical-data\": \"1\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"messages\": conversation_history,\n",
    "            \"temperature\": temperature,\n",
    "        },\n",
    "    ).json()\n",
    "    if \"choices\" not in response:\n",
    "        if print_errors:\n",
    "            print(response)\n",
    "        return None, conversation_history[:-1]\n",
    "    \n",
    "    assistant_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_message + \"\\n\"})\n",
    "    \n",
    "    return assistant_message, conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def get_correction_v2(\n",
    "    model_pages,\n",
    "    sleep_seconds=10,\n",
    "    n_tries=4,\n",
    "    **get_response_kwargs\n",
    "):\n",
    "    corrected_pages = []\n",
    "    conversation_history = None\n",
    "    for model_page in tqdm(model_pages):\n",
    "        corrected_lines = []\n",
    "        for model_line in tqdm(model_page.split(\"\\n\"), leave=False):\n",
    "            model_line = model_line.strip()\n",
    "\n",
    "            for try_n in range(n_tries):\n",
    "                corrected_line, conversation_history = get_response_v2(\n",
    "                    model_line + \" -> \", conversation_history, **get_response_kwargs\n",
    "                )\n",
    "                if corrected_line is not None:\n",
    "                    break\n",
    "                elif try_n == n_tries - 1:\n",
    "                    # last try faliled\n",
    "                    raise Exception(f\"Could not get response for {model_line}\")\n",
    "                else:\n",
    "                    time.sleep(sleep_seconds)\n",
    "\n",
    "            corrected_lines.append(corrected_line)\n",
    "        corrected_pages.append(\"\\n\".join(corrected_lines))\n",
    "    return corrected_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:27<00:00, 87.44s/it]\n"
     ]
    }
   ],
   "source": [
    "c = get_correction_v2([model_pages_test[0]], print_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рябикова\n",
      "Онъ дѣлялъ въ работникахъ и конца, и края что-то\n",
      "итель ударилъ его палкой по головѣ, отъ чего у не...\n",
      "и дѣлилась, будто бѣлая горлинка. Обращаясь къ Губер-\n",
      "натору. Въ вѣросходъ въ. А рѣшилъ. Смущаюсь.\n",
      "Больше никакихъ распоряженій не было сдѣлано. Вороемъ\n",
      "«Гласные возвратились на прежнія мѣста – ибо\n",
      "въ прочемъ случаѣ и острожные остались бы безъ.\n",
      "всякаго кожуха. \n",
      ".Вечеромъ читалъ піэссу – ядѣ чрезвычайно\n",
      "понравилась. – Беккеру также.\n",
      "10-го. Утромъ выѣхалъ въ Дѣдюхинское. Почувствовалъ в\n"
     ]
    }
   ],
   "source": [
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [12:13<00:00, 146.67s/it]\n"
     ]
    }
   ],
   "source": [
    "corrected_pages_test = get_correction_v2(model_pages_test, print_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рябикова\n",
      "Онъ дѣлялъ въ работникахъ и конца, и края что-то\n",
      "итель ударилъ его палкой по головѣ, отъ чего у не...\n",
      "и дѣлилась, будто бѣлая горлинка. Обращаясь къ Губер-\n",
      "натору. Въ вопросѣ въ А... Смутился.\n",
      "Больше никакихъ распоряженій не было сдѣлано. Вороемъ\n",
      "«Газовые возвратились на прежнія мѣста – ибо\n",
      "въ прочемъ случаѣ и острожные остались бы безъ.\n",
      "всякаго кожуха.\n",
      "Вечеромъ читалъ піэссу – ядѣ чрезвычайно\n",
      "понравилась. – Беккеру также.\n",
      "10-го. Утромъ выѣхалъ въ Дѣдюхинское. Почивалъ в\n"
     ]
    }
   ],
   "source": [
    "print(corrected_pages_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "for human_page, corrected_page in zip(human_pages_test, corrected_pages_test, strict=True):\n",
    "    human_lines = human_page.strip().split(\"\\n\")\n",
    "    corrected_lines = corrected_page.strip().split(\"\\n\")\n",
    "    if len(human_lines) == len(corrected_lines):\n",
    "        print(\"ok\")\n",
    "    else:\n",
    "        print(\"not ok: \", end=\"\")\n",
    "        print(len(human_lines), len(corrected_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER до GPT:     0.2167\n",
      "CER после GPT:  0.2062\n"
     ]
    }
   ],
   "source": [
    "# отдельные строки как примеры, учитываем историю\n",
    "print(f\"CER до GPT:    {calc_cer_from_pages(human_pages_test, model_pages_test, by_lines=False) : .4f}\")\n",
    "print(f\"CER после GPT: {calc_cer_from_pages(human_pages_test, corrected_pages_test, by_lines=False) : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER до GPT:     0.5991\n",
      "WER после GPT:  0.4879\n"
     ]
    }
   ],
   "source": [
    "# отдельные строки как примеры, учитываем историю\n",
    "print(f\"WER до GPT:    {calc_wer_from_pages(human_pages_test, model_pages_test) : .4f}\")\n",
    "print(f\"WER после GPT: {calc_wer_from_pages(human_pages_test, corrected_pages_test) : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:   Рябикова\n",
      "ChatGPT: Рябикова\n",
      "Human:   Рябчикова\n",
      "\n",
      "Model:   Онь дсиля въ работникахъ и конца, и кроалъ что-т\n",
      "ChatGPT: Онъ дѣлялъ въ работникахъ и конца, и края что-то\n",
      "Human:   Онъ де жилъ въ работникахъ у купца ; укралъ что-то\n",
      "\n",
      "Model:   ителъ удосилъ его палкой-по Голавѣ отъ чеи у не..\n",
      "ChatGPT: итель ударилъ его палкой по головѣ, отъ чего у не...\n",
      "Human:   и тотъ ударилъ его палкою по головѣ, отчаго у него\n",
      "\n",
      "Model:   и дѣлилаь удто бѣлая горянька. Обранясе къ Губер-\n",
      "ChatGPT: и дѣлилась, будто бѣлая горлинка. Обращаясь къ Губер-\n",
      "Human:   и сдѣлалась будто бѣлая горячка. Обратясь къ губер-\n",
      "\n",
      "Model:   натору. В - вросодъ въ, А ріес le . Смумаюсь.\n",
      "ChatGPT: натору. Въ вопросѣ въ А... Смутился.\n",
      "Human:   натору: В – f! Prens-le, pince-le! – Слушаюсь.\n",
      "\n",
      "Model:   Болья никакилъ раторяженійи не было сцѣлано. Вороемъ\n",
      "ChatGPT: Больше никакихъ распоряженій не было сдѣлано. Вороемъ\n",
      "Human:   Болѣе никакихъ распоряженій и не было сдѣлано. Впрочемъ,\n",
      "\n",
      "Model:   « гасовые возватлѣтсь на преженія мѣста – ибо\n",
      "ChatGPT: «Газовые возвратились на прежнія мѣста – ибо\n",
      "Human:   и часовые возвратились на прежніе мѣста – ибо\n",
      "\n",
      "Model:   въ прочиньномъ слугаѣ и острожные остались бы беъ.1\n",
      "ChatGPT: въ прочемъ случаѣ и острожные остались бы безъ.\n",
      "Human:   въ противномъ случаѣ и острожные остались бы безъ\n",
      "\n",
      "Model:   всякагю кожаува. ie\n",
      "ChatGPT: всякаго кожуха.\n",
      "Human:   всякаго караула.\n",
      "\n",
      "Model:   .Вечеромъ литалъ піэссу – ядѣ чревынойно\n",
      "ChatGPT: Вечеромъ читалъ піэссу – ядѣ чрезвычайно\n",
      "Human:   Вечеромъ читалъ піэссу – Дядѣ чрезвычайно\n",
      "\n",
      "Model:   понравилась. – бекаеру также.\n",
      "ChatGPT: понравилась. – Беккеру также.\n",
      "Human:   понравилась – Беккеру также.\n",
      "\n",
      "Model:   10-г. утромъ выѣхалъ въ дѣекаеевское. Почвалъ в\n",
      "ChatGPT: 10-го. Утромъ выѣхалъ въ Дѣдюхинское. Почивалъ в\n",
      "Human:   10-го утромъ выѣхалъ въ Алексеевское. Ночевалъ въ\n",
      "\n",
      "Model:   1856. Годъ май.\n",
      "ChatGPT: 1856. Годъ. Май.\n",
      "Human:   1856 годъ. Май\n",
      "\n",
      "Model:   д2. 23е – У 25. 26е. Въ Воскресенскомъ хлоно-\n",
      "ChatGPT: 23е. 25. 26е. Въ Воскресенскомъ хлѣбо-\n",
      "Human:   21. 22. 23е. 24. 25. 26е. Въ Воскресенскомъ. Хлопо-\n",
      "\n",
      "Model:   25г. Пустилъ Заводъ. Вечеромъ прiѣхалъ Ѳедоръ изъ\n",
      "ChatGPT: 25-го. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ\n",
      "Human:   25е. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ\n",
      "\n",
      "Model:   Стемой - тамъ в сi подышается. Въ Воскресенскомъ\n",
      "ChatGPT: Съ темой – тамъ всѣ подышаются. Въ Воскресенскомъ\n",
      "Human:   Степной - тамъ всё подвигается. Въ Воскресенскомъ\n",
      "\n",
      "Model:   съ Феврался постутилъ и управлястъ Зерунъ.\n",
      "ChatGPT: Съ февраля поступилъ и управлялъ Зерунъ.\n",
      "Human:   съ февраля поступилъ и управляетъ Зерунъ.\n",
      "\n",
      "Model:   4тло идеть завольна хорошо. Садку сдѣлалъ по\n",
      "ChatGPT: Дѣло идётъ довольно хорошо. Садку сдѣлалъ по\n",
      "Human:   У него идетъ довольно хорошо. Садку сдѣлалъ по\n",
      "\n",
      "Model:   прачоій Сторонѣ ларка отъдома къ ренѣ. Около-\n",
      "ChatGPT: правой сторонѣ ларка отъ дома къ рѣкѣ. Около-\n",
      "Human:   правой сторонѣ парка отъ дома къ рѣкѣ. Около\n",
      "\n",
      "Model:   дома проводить тоссе. Ставили Кри мнѣ Туле\n",
      "ChatGPT: дома проводить время. Ставили крыши мнѣ, Туле\n",
      "Human:   дома проводитъ шоссе. Ставили при мнѣ тум-\n",
      "\n",
      "Model:   бы оть дома къ Копонинѣ.\n",
      "ChatGPT: бы отъ дома къ Копонинѣ.\n",
      "Human:   бы отъ дома къ конюшнѣ.\n",
      "\n",
      "Model:   i чано утру выѣхалъ въ Москву. Послалъ за\n",
      "ChatGPT: И рано утромъ выѣхалъ въ Москву. Послалъ за\n",
      "Human:   27е. По утру выѣхалъ въ Москву. Послалъ за\n",
      "\n",
      "Model:   Кавъ кимь который – явился съ предноженіемъ отъ\n",
      "ChatGPT: Кавъкимъ, который явился съ предложеніемъ отъ\n",
      "Human:   Ковскимъ, который явился съ предложеніемъ отъ\n",
      "\n",
      "Model:   Ивача Пенелева о тирѣ. Сатомъ отѣъужанію\n",
      "ChatGPT: Ивача Пенелева о тирѣ. Съ этимъ отъѣзжанію\n",
      "Human:   Ивана Шепелева о мирѣ. Самсонъ отъѣзжаетъ\n",
      "\n",
      "Model:   съ Ревель. Кучилъ ему серебряныхъ вецій на 180.\n",
      "ChatGPT: съ Ревеля. Купилъ ему серебряныхъ вещей на 180.\n",
      "Human:   въ Ревель, купилъ ему серебряныхъ вещей на 180 р.\n",
      "\n",
      "Model:   с У Сазикова. Опедалъ Куботъ дни парвуки-\n",
      "ChatGPT: у Сазикова. Описалъ Кубокъ для парвуки-\n",
      "Human:   сереб. у Садикова. Отдалъ кубокъ для нарѣзки\n",
      "\n",
      "Model:   накнися Самной лову. хадиить\n",
      "ChatGPT: наклоняясь со мною ловилъ. Ходить\n",
      "Human:   надписи Самойлову. Надпись: \n",
      "\n",
      "Model:   3а снасніе почибавмихъ – Таланиц 1.\n",
      "ChatGPT: За снастіе погибающихъ – Талантъ 1.\n",
      "Human:   За Спасеніе погибавшихъ – таланту В.В.\n",
      "\n",
      "Model:   Са-нойsло ва презнательные А. В. Сухово– Ко.\n",
      "ChatGPT: Съ самой слова признательные А. В. Сухово–Ко.\n",
      "Human:   Самойлова признательные А.В. Сухово-Ко-\n",
      "\n",
      "Model:   23е. Сборы, на Выксу. Проищаные съ Санелономъ.\n",
      "ChatGPT: 23е. Сборы на Выксу. Прощаніе съ Санелономъ.\n",
      "Human:   28е. Сборы на Выксу. Прощаніе съ Самсономъ.\n",
      "\n",
      "Model:   тодалъ ъ тудъ патаки но 180 к. сереб, и те р. сер.а\n",
      "ChatGPT: Отдалъ туда пятаки на 180 к. серебра и те р. серебра.\n",
      "Human:   Продалъ 1 т. пудов патоки по 1.80 к. сер. и 1 т. р. сереб.\n",
      "\n",
      "Model:   вшсъ Рерстеру въ уплашу за апторать. Къ Саз\n",
      "ChatGPT: всё Рерстеру въ уплату за аппаратъ. Къ Саз-\n",
      "Human:   внесъ Ферстеру въ уплату за аппараты къ сахаръ-\n",
      "\n",
      "Model:   ному Lаводу. Вечеромь выкъхалъ на Выксиуъаи\n",
      "ChatGPT: ному Заводу. Вечеромъ выѣхалъ на Выксу.\n",
      "Human:   ному Заводу. Вечеромъ выѣхалъ на Выксу. \n",
      "\n",
      "Model:   24е.3ъ дорогъ. Хыюдно. простудался. Встрѣча въ\n",
      "ChatGPT: 24е. Съ дорогъ. Холодно. Простудился. Встрѣча въ\n",
      "Human:   29е. Въ дорогѣ. Холодно. Простудился. Встрѣча въ Вла-\n",
      "\n",
      "Model:   дувверѣ съ какимъ ополченскимъ о фидероме\n",
      "ChatGPT: доверіи съ какимъ-то ополченскимъ офицером.\n",
      "Human:   димірѣ съ какимъ ополченскимъ офицеромъ.\n",
      "\n",
      "Model:   Потулярность и всобщая, извѣсниеотъ Кренной\n",
      "ChatGPT: Популярность и всеобщая извѣстность отъ Кренной\n",
      "Human:   Популярность и всеобщая извѣстность Кречинского.\n",
      "\n",
      "Model:   Его ужа играли вовсй Россіи. Успѣхъ одинъ весен\n",
      "ChatGPT: Его уже играли во всей Россіи. Успѣхъ одинъ весен.\n",
      "Human:   Его уже играютъ во всей Россіи. Успѣхъ одинъ вездѣ.\n",
      "\n",
      "Model:   30е. въ 11 часовъ утра никѣмъ неождашный.\n",
      "ChatGPT: 30е. Въ 11 часовъ утра никѣмъ неожидаемый.\n",
      "Human:   30е въ 11 часовъ утра никѣмъ неожиданный пріе-\n",
      "\n",
      "Model:   халъ на Выксу - отецъ былъ радъ онъ посторѣй\n",
      "ChatGPT: ехалъ на Выксу – отецъ былъ радъ, онъ постарѣл.\n",
      "Human:   халъ на Выксу - отецъ былъ радъ, онъ постарѣлъ\n",
      "\n",
      "Model:   иѣсколько потолстѣлъ и въ голось замѣжна нере-\n",
      "ChatGPT: и нѣсколько потолстѣлъ, и въ голосѣ замѣтна нѣре-\n",
      "Human:   нѣсколько потолстѣлъ и въ голосѣ нѣсколько перемѣнился,\n",
      "\n",
      "Model:   нѣтъ твердости. На Выксѣ семра соловая,\n",
      "ChatGPT: нѣтъ твердости. На Выксѣ зима суровая,\n",
      "Human:   нѣтъ твердости. На Выксѣ сосѣди Соловые, сестра\n",
      "\n",
      "Model:   Сальяцъ. Пнк. Тепелилъ и в миховскій. Пиколой\n",
      "ChatGPT: Сальяцъ. Печь. Теплился и въ мѣховскій. Покой.\n",
      "Human:   Сальясъ, Ник. Шепелевъ и Дмоховскій. Николай\n",
      "\n",
      "Model:   Гроть 1е. Рано утромъсъ гориныемъ выѣхалъ на сио.\n",
      "ChatGPT: Гротъ 1е. Рано утромъ съ Гориньемъ выѣхалъ на село.\n",
      "Human:   Іюнь. 1е. Рано утромъ съ Соринымъ выѣхалъ на Снаведь.\n",
      "\n",
      "Model:   Мвгупть. 3гo. Уѣхалъ въ Петербургъ ибо дѣло приняло дурной\n",
      "ChatGPT: Могутъ. 3-го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной\n",
      "Human:   Августъ 3го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной\n",
      "\n",
      "Model:   оборомъ въ Мни 1öen. Натало тяжекое время. Сѣрвсаколо-\n",
      "ChatGPT: оборотъ въ мнѣ. Началось тяжёлое время. Сѣрьёзно коло-\n",
      "Human:   оборотъ въ Мин. Юст. Настало тяжелое время. Связь съ Голи-\n",
      "\n",
      "Model:   крѣнокъ. Ходилъ нѣсколько разъ греть на подку – и\n",
      "ChatGPT: крѣнокъ. Ходилъ нѣсколько разъ грѣться на подку – и\n",
      "Human:   крѣпокъ. Ходилъ нѣсколько разъ гресть на лодку - и\n",
      "\n",
      "Model:   купался въ шѣѣ до наловмы Августа.\n",
      "ChatGPT: купался въ рѣкѣ до половины Августа.\n",
      "Human:   купался въ Невѣ съ половины августа.\n",
      "\n",
      "Model:   Сенслябрь. Въ Петербургѣ. Подалъ запику М. Фв о\n",
      "ChatGPT: Сентябрь. Въ Петербургѣ. Подалъ записку М. Ф. о\n",
      "Human:   Сентябрь. Въ Петербургѣ. Подалъ записку м. ф-ов о\n",
      "\n",
      "Model:   предкриятіи въ 8ж. Россіи. Отаровили на Выксу и\n",
      "ChatGPT: предпріятіи въ Юж. Россіи. Отправили на Выксу и\n",
      "Human:   предпрiятiи въ Юж. Россiи. Отправился на Выксу и\n",
      "\n",
      "Model:   заклочилъ у словсе съ vнк. Иется. Прiѣхалъ обранна\n",
      "ChatGPT: заключилъ условіе съ инж. Иется. Пріѣхалъ обратно.\n",
      "Human:   заключилъ условие с Ник. Шепел. Прiѣхалъ обратно\n",
      "\n",
      "Model:   въ Петербургъ. 13ге. Нояюря. Сововые сыня и мамаковъ\n",
      "ChatGPT: въ Петербургъ. 13-го Ноября. Совѣщаніе съ сыномъ и Мамаковым.\n",
      "Human:   въ Петербургъ 13го ноября. Соловые. Соня и Маменька въ\n",
      "\n",
      "Model:   Петербургѣ. Жиднь въ свстицѣ Демдова. Постояно\n",
      "ChatGPT: Петербургѣ. Жизнь въ свѣтлицѣ Демидова. Постоянно\n",
      "Human:   Петербургѣ. Жизнь въ гостиницѣ Демидова. Постановилъ\n",
      "\n",
      "Model:   ходилъ въ Дерошу но устрамъ. Окочилъ 2оп и 3 м Ѳекетъ.\n",
      "ChatGPT: ходилъ въ Дерошу по утрамъ. Окончилъ 2-й и 3-й мѣсяцъ.\n",
      "Human:   ходить къ Депону по утрамъ. Окончилъ 2ой и 3iй актъ. \n",
      "\n",
      "Model:   Дѣло въ Гомуд. Солѣтѣ. вбр Торги на вичновые\n",
      "ChatGPT: Дѣло въ Гомель. Совѣтѣ. Въ Торги на вѣщевые\n",
      "Human:   Дѣло въ Госуд. Советѣ. Декабрь Торги на винтовые\n",
      "\n",
      "Model:   Корабни. Конывъ и Шульчмъ въ Петербургѣ. Декабрь.\n",
      "ChatGPT: Корабли. Коновъ и Шульцъ въ Петербургѣ. Декабрь.\n",
      "Human:   корабли. Копьевъ и Шульгинъ въ Петербургѣ. Декабрь. \n",
      "\n",
      "Model:   возвранинся въ Москву.\n",
      "ChatGPT: возвратился въ Москву.\n",
      "Human:   Возвратился въ Москву. \n",
      "\n",
      "Model:   12f4. Годъ. Новый годъ нажелзной дорогѣ. Былъ въ Доскре-\n",
      "ChatGPT: 1854. Годъ. Новый годъ на желѣзной дорогѣ. Былъ въ Москве.\n",
      "Human:   1854 годъ. Новый годъ на желѣзной дорогѣ. Былъ в Воскре-\n",
      "\n",
      "Model:   сискомъ. 15 чеила выѣхалъ на Выксу. Амнлte Гол.\n",
      "ChatGPT: спискомъ. 15-го числа выѣхалъ на Выксу. Аннѣ Гол.\n",
      "Human:   сенскомъ. 15 числа выѣхал на Выксу. Anette Гол. \n",
      "\n",
      "Model:   Ныеса читалась въ уепѣхомъ. Въ оРевранѣ,\n",
      "ChatGPT: Пьеса читалась съ успѣхомъ. Въ Февралѣ,\n",
      "Human:   Пьесса читалась съ успехомъ. Въ февралѣ\n",
      "\n",
      "Model:   должъ былъ ѣхатъ въ Москку по полоду насавшается\n",
      "ChatGPT: долженъ былъ ѣхать въ Москву по поводу насущается\n",
      "Human:   долженъ былъ выѣхать въ Москву по поводу начавшагося\n",
      "\n",
      "Model:   Слѣхмвся. Вздилъ на нѣскольоо дней въ Пентербургъ.\n",
      "ChatGPT: Съ лѣгкостью. Въѣхалъ на нѣсколько дней въ Петербургъ.\n",
      "Human:   слѣдствiя. Ѣздилъ на нѣсколько дней в Петербургъ.\n",
      "\n",
      "Model:   Нталъ охоимисьихъ вещю ченобы охотиться.\n",
      "ChatGPT: Снялъ охотничьихъ вещей, чтобы охотиться.\n",
      "Human:   Покупалъ охотничьихѣ вещей, чтобы охотиться. \n",
      "\n",
      "Model:   2гo мадна на первой не дѣли воротилси въ Москву.\n",
      "ChatGPT: 2-го марта на первой недѣле воротился въ Москву.\n",
      "Human:   1гo марта на первой недѣлѣ воротился въ Москву. \n",
      "\n",
      "Model:   для пріiема Дамь. Онъ пріѣхали поздно. Обѣдали въ 6-м часу был\n",
      "ChatGPT: для пріёма дамъ. Они пріѣхали поздно. Обѣдали въ 6-м часу. Был\n",
      "Human:   для пріема дамъ. Онѣ пріѣхали поздно. Обѣдали въ 6мъ часу – было\n",
      "\n",
      "Model:   довольна весел. – Я очно вечеко игралъ въ карты\n",
      "ChatGPT: довольно весел. – Я очно вечеромъ игралъ въ карты.\n",
      "Human:   довольно весело. – Я очень весело игралъ въ карты. –\n",
      "\n",
      "Model:   нѣлтъ яЯ отправичъ Семна нъ В Туму Запродать будущаго Cахора\n",
      "ChatGPT: Нѣлъ я. Я отправилъ Семена въ Тулу запродать будущаго сахара.\n",
      "Human:   нѣтъ. Я отправилъ Семена Ив. въ Тулу запродать будущаго сахара.\n",
      "\n",
      "Model:   228-е Лmmи яяшалъ рао Споляничалъ. Рапимывалъ и отпровилъ Выю-\n",
      "ChatGPT: 28-е. Лѣтомъ я решалъ разное. Споряничалъ. Расписывалъ и отправилъ Выю-\n",
      "Human:   28е. Всталъ рано. Столярничалъ. Разсчитывалъ и отправилъ Вык-\n",
      "\n",
      "Model:   Симкилъ 18 человѣсъ. Но обратныхъ пододовъ ратробовалъ изъ Москвы\n",
      "ChatGPT: Снялъ 18 человѣкъ. На обратныхъ поездахъ попробовалъ изъ Москвы.\n",
      "Human:   сунскихъ 18 человѣкъ. На обратныхъ подводахъ затребовалъ изъ Москвы\n",
      "\n",
      "Model:   Либили, картинъ, броизу. Естя прѣ пиводь буду жить 7 Россіи – накъ\n",
      "ChatGPT: Купили картинъ, бронзу. Если при поводѣ буду жить въ Россіи – такъ\n",
      "Human:   мебель, картины, бронзу. Если я гдѣ-нибудь буду жить въ Россіи – такъ\n",
      "\n",
      "Model:   это сдѣся – въ кобылимкѣ..\n",
      "ChatGPT: это здѣсь – въ Кобылинкѣ.\n",
      "Human:   это здѣсь – въ Кобылинкѣ.\n",
      "\n",
      "Model:   Замѣчательныой раскаръ О помещикѣ Малиновскомъ убинноъ се\n",
      "ChatGPT: Замѣчательной рассказъ о помещикѣ Малиновскомъ, убившемъ се...\n",
      "Human:   Замѣчательный расказъ о помѣщикѣ Маниловскому, убитомъ его\n",
      "\n",
      "Model:   костьяноми. Какъ Замѣнно это было Сильной странно.\n",
      "ChatGPT: костями. Какъ замѣтно это было сильно странно.\n",
      "Human:   крестьянами. Какъ замѣтно это была сильная, страшно\n",
      "\n",
      "Model:   4.онъ довева Крестьямъ до большаго блаю состоянія и богати.\n",
      "ChatGPT: Онъ довелъ крестьянъ до большаго благосостоянія и богатства.\n",
      "Human:   онъ довелъ крестьянъ до большого благосостоянія и богат-\n",
      "\n",
      "Model:   1ства, получилъ имѣніе разоренное– и кресетьяхъ противишотія –\n",
      "ChatGPT: состоянія, получилъ имѣніе разоренное – и крестьянъ противящихся –\n",
      "Human:   ства, получивъ имѣніе разоренное и крестьянъ прожившихся.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_page, corrected_page, human_page in zip(model_pages_test, corrected_pages_test, human_pages_test, strict=True):\n",
    "    for model_line, corrected_line, human_line in zip(model_page.split(\"\\n\"), corrected_page.split(\"\\n\"), human_page.split(\"\\n\"), strict=True):\n",
    "        print(f\"Model:   {model_line}\")\n",
    "        print(f\"ChatGPT: {corrected_line}\")\n",
    "        print(f\"Human:   {human_line}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Коррекция после фикса с паддингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_path = Path(\"/Users/v.p.zykov/Downloads/telegram\")\n",
    "\n",
    "with open(eval_results_path / \"eval_train.pkl\", \"rb\") as f:\n",
    "    eval_train = pickle.load(f)\n",
    "\n",
    "with open(eval_results_path / \"eval_test.pkl\", \"rb\") as f:\n",
    "    eval_test = pickle.load(f)\n",
    "\n",
    "with open(eval_results_path / \"eval_val.pkl\", \"rb\") as f:\n",
    "    eval_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['str_preds', 'str_gt', 'cer', 'wer', 'cers', 'wers'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from basic.utils import edit_cer_from_list, nb_chars_from_list, edit_wer_from_list, nb_words_from_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cer_from_list(gt: list[str], pred: list[str]):\n",
    "    return edit_cer_from_list(gt, pred) / nb_chars_from_list(gt)\n",
    "\n",
    "def calc_wer_from_list(gt: list[str], pred: list[str]):\n",
    "    return edit_wer_from_list(gt, pred) / nb_words_from_list(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert calc_cer_from_list(eval_test[\"str_gt\"], eval_test[\"str_preds\"]) == eval_test[\"cer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert calc_wer_from_list(eval_test[\"str_gt\"], eval_test[\"str_preds\"]) == eval_test[\"wer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt_v2(val_gt: list[str], val_preds: list[str], train_gt: list[str], train_preds: list[str], limit_train_lines=500):\n",
    "    prompt = f\"\"\"Твоя задача - корректировать входной текст, исправляя в нем ошибки.\n",
    "Это текст, распознанный моделью компьютерного зрения с рукописей. Рукописи написаны на русском языке 19 века (также иногда присутствуют другие языки).\n",
    "Цель - получить максимально близкий к рукописи вариант расшифровки.\n",
    "Модель допускает много ошибок в распознавании символов.\n",
    "Исправляй только самые явные и понятные места. Если фрагмент текста сложно разобрать, то сохраняй его в том же виде, в котором и получил.\n",
    "Сохраняй имена собственные и числительные как есть. Сохраняй исходную последовательность слов.\"\"\"\n",
    "    examples = \"Правильный текст из обучающей выборки:\\n\"\n",
    "    for i, (human_line, model_line) in enumerate(zip(train_gt, train_preds, strict=True)):\n",
    "        examples += f\"{human_line}\\n\"\n",
    "        if i + 1 >= limit_train_lines:\n",
    "            break\n",
    "    examples += \"\\n\\nПримеры исправлений, требующихся от тебя:\\n\"\n",
    "    for i, (human_line, model_line) in enumerate(zip(val_gt, val_preds, strict=True)):\n",
    "        examples += f\"{model_line} -> {human_line}\\n\"\n",
    "    return prompt + \"\\n\\n\" + examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_train[\"str_preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Твоя задача - корректировать входной текст, исправляя в нем ошибки.\n",
      "Это текст, распознанный моделью компьютерного зрения с рукописей. Рукописи написаны на русском языке 19 века (также иногда присутствуют другие языки).\n",
      "Цель - получить максимально близкий к рукописи вариант расшифровки.\n",
      "Модель допускает много ошибок в распознавании символов.\n",
      "Исправляй только самые явные и понятные места. Если фрагмент текста сложно разобрать, то сохраняй его в том же виде, в котором и получил.\n",
      "Сохраняй имена собственные и числительные как есть. Сохраняй исходную последовательность слов.\n",
      "\n",
      "Правильный текст из обучающей выборки:\n",
      "вечеръ. Всталъ въ 6мъ часу.\n",
      "21е. Перемѣна погоды. Дождикъ, свѣжо, всталъ\n",
      "въ 6мъ часу. Купался в дождь. Гребъ очень мало. Чув-\n",
      "ствуя холодъ противъ по Александровскому саду.\n",
      "3 раза. Согрѣлся и ощутилъ крѣпость. Переводъ шелъ\n",
      "отлично. – Чувство крѣпости во весь день.\n",
      "22е, 23е. 24е Особенно не чувствов. себя хорошо - былъ\n",
      "маленькiй флюсъ. 24е. Не купался. Николай прiѣхалъ съ Выксы.\n",
      "24е. Получилъ копiю съ разбойнической бумаги и сѣлъ\n",
      "писать отпоръ. 25е – 26е. Писалъ отпоръ, работа\n",
      "тяжелая. Сила шла на убыль.\n",
      "27. День лѣтнiй. Вода согрѣлась. Купался посреди\n",
      "рѣки, плылъ въ длину. От купанья чувствовалъ себя хорошо\n",
      "подконец худо. Вечеръ чудный, теплый. - Шепелев на лодкѣ\n",
      "28. День летнiй. Вода 16 °. Купался серёдъ рѣки.\n",
      "Отправилъ отпоръ въ Петербургъ. Чувствовалъ себя\n",
      "средственно. Вечеръ лѣтнiй чудесный.\n",
      "29е. Утро чудное. Всталъ въ 5 час. Купался в Лужникахъ.\n",
      "Кн. Кат. Гагарина была у графа Блудова. Днемъ\n",
      "работалъ Гимнастику. Вечеромъ катался на лодкѣ\n",
      "отлично. Возвращаясь, чувствовалъ себя легко и\n",
      "Духомъ былъ у cамой природы.\n",
      "30е. На лодкѣ. Купался середъ рѣки.\n",
      "31е. На лодкѣ. Купался середъ рѣки. Воздухъ холоденъ,\n",
      "вода еще тёпла. Гимнастика. Купался въ\n",
      "купаться, ѣстъ фрукты и не забочусь ни о чемъ.\n",
      "23-е число. Прiѣхала сестра Соня. Продолжаю\n",
      "утрами ходить на лодку и гресть. Вѣтеръ\n",
      "и холодъ. Эта прогулка производит на меня\n",
      "то же влiян, какъ купанiе. Я хожу въ легкомъ\n",
      "пальто и скидаю его. Сначала озябаю самъ и\n",
      "особенно руки, но потомъ всё крѣпнетъ, и я\n",
      "возвращаюсь въ хорошемъ состоянiи ... - Скоро кончится\n",
      "и гребля работа. Надо будетъ найти себѣ рукодѣлiе.\n",
      "праздными разговорами. Высланы на Выксу картины.\n",
      "27-е. Всталъ рано и отправился въ домъ, гдѣ и\n",
      "завтракалъ. - Обѣдалъ у сестры.\n",
      "28е число. Разстроенъ вѣстью изъ Петербурга.\n",
      "17е. Изъ Степи привели лошадей. - Anaїs, письмо\n",
      "къ Сонѣ о полученіи ею медали. Яшвиль пріѣхалъ изъ\n",
      "жительное въ теченіе нѣсколькихъ дней.\n",
      "18е. Всталъ рано. Полный туалетъ. – Свѣжо и крѣпко.\n",
      "Въ Гимнастикѣ движенье хорошо. P.f. 80. –.\n",
      "Вечеръ у Потулова.\n",
      "Victor. Вина не пилъ, ѣлъ немного – послѣ\n",
      "обѣда хорошо. Легъ въ 10 ч.\n",
      "21е. Читалъ піэссу Садовскому – неудача.\n",
      "До конца мѣсяца состояніе среднее.\n",
      "Переводъ шелъ мало.\n",
      "Ноябрь. 1. 2. 3е прошли въ суматохѣ внѣшно-\n",
      "сти и безсознательности. Началъ столярничать.\n",
      "4е. Получилъ утромъ свободу. Плацъ-адъютантъ\n",
      "Дьячконскій, арестовавшій меня, пріѣхалъ на\n",
      "гауптвахту и самъ привезъ въ домъ къ Ма-\n",
      "тушкѣ. Обѣдали вмѣстѣ Самсонъ и Поту-\n",
      "ловъ. Гимнастика шла хорошо, во многихъ\n",
      "движеніяхъ есть успѣхи. Въ это время\n",
      "сталъ прыгать чрезъ лошадь чисто. –.\n",
      "5е. Маменька уѣхала въ Петербургъ обратно. –.\n",
      "6е. Столярничалъ мало. Вечеромъ у Пуаре –\n",
      "борьба съ Пуаре. Я его поборолъ. Спалъ крѣпко.\n",
      "† 7e. Всталъ сильно. Столярничалъ. – P.f.\n",
      "Былъ у Луизы. – Это её день.\n",
      "8е. Столярничалъ – обѣдалъ у Самсона.\n",
      "Довольно въ духѣ. Антонъ Голиц. пріѣхалъ\n",
      "изъ Петербурга. Вечеръ вмѣстѣ.\n",
      "9е. Всталъ рано. Довольно сильно. Ничего не\n",
      "дѣлалъ. Подалъ просьбу въ Над. судъ. Въ Гимнастикѣ\n",
      "не работалъ. Антонъ Голиц. уѣхалъ въ Гжатскъ.\n",
      "10е. Всталъ рано - ничего не дѣлалъ. Вечеромъ въ\n",
      "Гимнастикѣ у Пуаре. Чувствовалъ себя\n",
      "сильно. Прыгалъ хорошо. – . Сильный снѣгъ и къ вечеру\n",
      "морозъ. – Вечеръ у кн. Кат. Гагариной и Нат. Андре.\n",
      "Соловой. –\n",
      "11е. Хлопоты по устройству дома разладица\n",
      "вѣсь день въ хлопотахъ. Вечеромъ съ An. въ духѣ\n",
      "и силѣ. За прошедшіе дни, работая въ Гимнастикѣ\n",
      "такъ укрѣпился, что всё дни былъ въ силѣ и,\n",
      "кажется, сильнѣе лета. – Эти дни Pf 100°\n",
      "12. Стала зима. Санный путь.\n",
      "Хлопоты по устройству дома. – Вѣсь день. –\n",
      "Вечеромъ до 2х часовъ у Кат. Гагариной.\n",
      "13е. Странная головная боль вѣсь день. –\n",
      "Стоимость патоки по пробѣ, сдѣланной\n",
      "Ѳедоромъ – на сей годъ: на заварку 114 пудъ.\n",
      "лѣсу 16 п по 1,30 - р. ас.           20.80. –\n",
      "угля 3 п. 1,25                     3.75.\n",
      "кислоты 32ф. 0,17                5.60.    Расходу на пудъ.\n",
      "дровъ ело.3  14 р. ас.    –         49.     Полагаю варитъ въ\n",
      "жал. мастеру 15 к. съ пуда  –      17.10.    годъ 10 т. пуд.\n",
      "рабочимъ 12 чел. 70 к. съ харчъ.  …  8.40.\n",
      "за заведеніе 5 к. съ пуда     –      5.70.\n",
      "провозъ въ Мос. 15 копъ.съ пуда  – 17.40.\n",
      "лавка и приказчикъ по 50 к. съ пуда  57.\n",
      "Итого въ сутки 190. 45 к. сер.\n",
      "Поле въ Воскресенскомъ и урожай за\n",
      "сей 1854 годъ.\n",
      "Ржи въ Воскрес. 12 1/2 десятинъ    5.30 коп. по 3 мер. до 200 четв.\n",
      "въ Пуч.    8 десятинъ     169 по 1/2 мер 32 четв.\n",
      "овса         22 1/2      310 по 1 чет. 3 гар. 390\n",
      "сѣна ....................................................... 8288 пуд.\n",
      "картофелю ................................................... 1904 чет\n",
      "муки вышло ..............\n",
      "поставилъ мнѣ картоф.. 1688 четвер по 60 к сер.\n",
      "на сумму 1013 р. 32 к. сереб. –\n",
      "14. 15. 16. 17. 18. Нѣсколько дней сряду большое\n",
      "разстройство, головная боль, слабость, тяжесть.\n",
      "Полагаю, отъ сильной тревоги вслѣдствіе про-\n",
      "пажи самыхъ завѣтныхъ вещей моей Луизы.\n",
      "Къ концу ноября начало здоровье справляться.\n",
      "Въ началѣ декабря опять сталъ вставать\n",
      "рано, занялся переводомъ постоянно утромъ.\n",
      "4е декабря купилъ машину купальную, и\n",
      "жизнь стала еще правильнѣе.\n",
      "Порядокъ дня въ декабрѣ 1854 года.\n",
      "Встаю въ 6-тъ часовъ. Сей часъ умываюсь холодной водою\n",
      "и окатываю голову. Потомъ сей часъ въ машину.\n",
      "Вода въ ней около 17° Реомъ. Пускаю дождь съ низу\n",
      "и дѣлаю тогда petite toilette. Потомъ пускаю\n",
      "дождь боковой, потомъ задаю водою сверху. Потомъ\n",
      "одѣваюсь и иду строгать. Въ 7 часовъ сажусь\n",
      "за переводъ. (Перевожу изъ Фіи исторіи Passion). Кофій въ\n",
      "8 часовъ. 10 1/2 у Толбузина чай, ворочаюсь отъ Толбузина.\n",
      "Текущія занятія, переписка. Выхожу или съ визитами,\n",
      "или въ Гимнастику. Обѣдаю дома. Вечеръ дома Anais.\n",
      "Въ 11-м часу ложусь спать. – .\n",
      "Maximum. Pf.100°. 23. An. уѣхала въ Петербургъ.\n",
      "25. Рождество. Обѣдалъ у сестры Сальясъ –\n",
      "26. Обѣдалъ у дяди Ал. Алекс. – весьма\n",
      "1854. Декабрь\n",
      "en verve. Большой разговоръ съ Алмазо-\n",
      "вымъ о цивилизаціи. 27. Обѣдъ у\n",
      "тьевъ.\n",
      "31е. Перешелъ половину переводи-\n",
      "мой мною книги Гег. Фія исторіи.\n",
      "У Билы вѣшался на вѣсахъ – я\n",
      "вѣшу 4 п. 27 ф. въ теченіе лѣта я\n",
      "пріобрѣлъ три фунта.\n",
      "1855 годъ. –\n",
      "1е генв. Вечеръ 31го провелъ съ Самсономъ, читалъ ста-\n",
      "тью Finances de la Guerre. Спалъ хорошо.\n",
      "Всталъ не рано и пишу сіи строки.\n",
      "2е. 3 е. 4 е. Приготовленія къ отъѣзду на охоту\n",
      "за лосями къ Потулову.\n",
      "5 го. Выѣхалъ къ Потулову.\n",
      "7 го. Пріѣздъ къ нему въ село Дмитровское.\n",
      "Усталъ.\n",
      "12. 13. 14. Охота. Холодъ, я его переношу отлично.\n",
      "Возвращался изъ лѣсу домой, тѣло закаливается.\n",
      "13. Убилъ лося. 14е. Охота.\n",
      "15е. Выѣздъ.\n",
      "16е. У дяди Ник. Иван. въ Калугѣ.\n",
      "18. Возвратился отъ Потулова съ охоты. Чув-\n",
      "ствовалъ себя весьма сильно. Pt. днемъ. –.\n",
      "19. Генваря. Пріѣздъ Василья Макарова – получено оброку\n",
      "2300 р. сереб. Pt. Каждую ночь 90°\n",
      "20. Генваря. Чувствовалъ себя въ силѣ. Утромъ располо-\n",
      "жился къ дѣлу. Переводъ шелъ мало. Занимался дѣлами.\n",
      "21. Пріѣхалъ Лукьяновъ. Занимался съ нимъ. Именины\n",
      "Енюшки.\n",
      "22. Открытіе у меня бильярда. Утромъ писалъ\n",
      "письма и бумаги къ отцу, отравляя къ нему\n",
      "съ докладомъ Лукьянова. У меня обѣдали до\n",
      "1855. февр. и мартъ.\n",
      "18. Получено извѣстіе о Смерти Императора\n",
      "чрезъ Корша, который въ 2 часа дня зашелъ\n",
      "ко мнѣ, чтобы объявить мнѣ. –.\n",
      "Всё это время чувствовалъ себя въ силѣ чрез-\n",
      "вычайно, какъ еще никогда. Занятія шли\n",
      "правильно, переводъ двинулся. – Къ концу февраля\n",
      "пополнѣлъ, прибыло по вѣсу 4 ф. тѣло очень\n",
      "крѣпко. Въ Гимнастикѣ всѣ въ трико и\n",
      "сталъ хорошо прыгать на лошадь.\n",
      "Свиданіе съ N. cталъ ложиться поздно –\n",
      "сталъ разстраиваться много здоровьемъ –.\n",
      "поздно, не столярничалъ и потому и\n",
      "сталъ идти подъ гору. Занятій не было.\n",
      "15. Ѣздилъ въ Воскресенское. Промои путь испортили,\n",
      "возка дровъ остановила сіе; зажоръ. – Возвратился\n",
      "19. Плохо. Сильно не въ духѣ – нѣсколько дней уже\n",
      "ничто не дѣлалъ. Аппетитъ сталъ лучше.\n",
      "Тѣло сдало и обмякло. Надо работать фи-\n",
      "21е. Состояніе то же. Собираюсь на Выксу. Утренній морозъ\n",
      "держитъ еще путь. Денежные хлопоты. 9 мелкихъ быковъ продалъ\n",
      "по 13 р. сер.\n",
      "24. Выѣхалъ на Выксу. Дорога почти испорти-\n",
      "лась. Снѣгу на поляхъ мало.Отъ Владиміра еще\n",
      "меньше. Отъ Мурома до Выксы вовсе нѣтъ.Пере-\n",
      "права чрезъ Оку подъ Муромомъ. Одна лошадь про-\n",
      "валилась – пріѣхалъ на Выксу верхомъ въ великую\n",
      "пятницу. Макаръ подмочилъ всѣ вещи.\n",
      "27. Святая. День удивительный – въ саду показалась\n",
      "первая травка.\n",
      "28. Первая охота. Показались бекасы. Николай\n",
      "убилъ одного. Обѣдали въ полѣ. Весенній день. Ясно\n",
      "и тепло.\n",
      "29. 30. Дни ясные – сбираемся въ Траслею. –\n",
      "31. Выѣхали на охоту въ Траслею. Въ Царицыномъ\n",
      "лугу убилъ перваго бекаса.\n",
      "Апрѣль. 1е. Въ Траслее. Охота за глухими\n",
      "тетеревами. Вечеръ въ болотѣ на Царицыномъ лугу.\n",
      "1855. Апр.\n",
      "2е. Утро за полевыми тетеревами. Воротился на\n",
      "Выксу. Не усталъ – спалъ днемъ. Расположенiе духа хоро-\n",
      "шее. Тѣло от этихъ двухъ дней поправилось.\n",
      "ЗВечеръ провелъ у А. А. Заячiй пер. - День удивитель\n",
      "3. Утро занялся отлично – былъ какой-то порывъ,\n",
      "ясность, быстрота. За симъ завтракалъ во\n",
      "флигелѣ у Николая и имелъ съ нимъ большой\n",
      "разговоръ о семейныхъ дѣлахъ. Вечеромъ читалъ Коме-\n",
      "дiю Кн. А.Д. Гол., Кн. Льву Голиц., Графу Кут. Николаю\n",
      "и доктору. Она начинаетъ имѣть успѣхъ. День\n",
      "не токмо майский, но даже лѣтний.\n",
      "4е. Утро. Обдался водою. Гулялъ. Утро удиви-\n",
      "тельное. День майскiй – въ саду Выксунскомъ\n",
      "вѣзде показалась трава. Вечеръ чудный.\n",
      "5-е. Утро. Обдался водою. Работалъ в пали-\n",
      "садникѣ немного. Приказалъ приготовить\n",
      "себѣ гряду. Работа шла тяжело. Но днемъ\n",
      "чувствовалъ себя лучше. Занимался до обѣда.\n",
      "Евангелiе. Переводъ идетъ порядочно.\n",
      "6-е. Утро обдался. Работалъ въ саду - садилъ\n",
      "гряду малины. Работа шла тяжко. Евангелiе.\n",
      "Переводъ. Чтенiе до обѣда. Написалъ кое-что\n",
      "свое. День свѣжѣе.\n",
      "одѣлся и чувствую себя отлично. Не понимаю, какъ\n",
      "у меня нѣтъ довольно твердости, чтобы удерживать\n",
      "этотъ порядокъ жизни - это просто свое ради\n",
      "благополучія. Даю себѣ обѣтъ письменно - во\n",
      "что бы то ни стало – этотъ порядокъ, для\n",
      "труда и въ трудѣ - если не исполню, отказы-\n",
      "ваюсь отъ имени человѣка съ характеромъ.\n",
      "13е. В Траслее - убилъ 2-х бекасовъ и гаршнепа.\n",
      "День чудный - жарко.\n",
      "1855 Апрѣль.\n",
      "Газонъ совсѣмъ зеленый.\n",
      "16. День лѣтній. Гулялъ съ Голицыными въ\n",
      "гривенник. Вечер чудный и тёплый. до 17 0\n",
      "17. С утра необыкновенно тепло - к вечеру стало\n",
      "въ саду, нѣсколько простуженъ.\n",
      "18. Всталъ не рано, болитъ спина, не работалъ.\n",
      "Переводъ не дѣлалъ нѣсколько дней, а соста-\n",
      "влялъ отчетъ для отца въ полученныхъ суммахъ.\n",
      "Вечеромъ писалъ письмо къ Дмоховскому о заказѣ для\n",
      "желѣзной дороги подкладокъ и болтовъ.\n",
      "Представилъ отцу отчетъ въ особыхъ суммахъ.\n",
      "Извѣстіе о прорывѣ Ижевской плотины.\n",
      "Разговоръ о предположеніи о семъ съ отцомъ.\n",
      "21. Ѣздилъ на Ставецъ по заказу на\n",
      "Варшавскую дорогу. Холодно.\n",
      "23. Вечеромъ въ 10 часовъ пріѣхалъ въ Москву.\n",
      "24. Вечеромъ уѣхалъ въ Воскресенское. День ясный\n",
      "тепло. Береза распускается. Самбукъ и сирень\n",
      "раскрылись на 1 1/2 дюйма.\n",
      "25. Утромъ пріѣхалъ въ Москву и далъ подписку\n",
      "объ рукоприкладствѣ по нещастному дѣлу въ\n",
      "26. Утромъ выѣхалъ въ Воскресенское верхомъ.\n",
      "1855 год. Май и Апрель.\n",
      "Обѣдалъ дома съ сестрой Софьей. Вечеръ у\n",
      "28. День жаркій. Соня уѣхала на Выксу.\n",
      "Сборы въ Воскресенское.\n",
      "30е. Уѣхалъ въ Воскресенское – время удивительное –\n",
      "всѣ кустарники въ полномъ цвѣту – благоуханіе\n",
      "необыкновенное. – Грудь широко дышитъ – въ\n",
      "членахъ сила, хочется какого-то дѣла –\n",
      "кажется, много бы передѣлалъ. Должно по поводу\n",
      "этихъ ощущеній замѣтить, что въ теченіе послѣднихъ\n",
      "лѣтъ въ моемъ организмѣ произошла такая\n",
      "перемѣна: несчастное событіе потрясло мой\n",
      "организмъ страшно: собственно нервная функція\n",
      "нервной системы начала слабѣть: обоняніе, бывшее\n",
      "необыкновенно, зрѣніе, бывшеѣ весьма сильное, ослабѣли,\n",
      "аппетитъ и вкусъ также ослабѣли, аппетитъ пропалъ.\n",
      "Зато занятіе Гимнастикой укрѣпило мускулы – уста-\n",
      "лость я сталъ переносить отлично. Эротическое увощу-\n",
      "въ функцію мускула, а не нерва.\n",
      "Май 1е. 2е. 3е. Въ Воскресенскомъ – цѣлый день въ полѣ\n",
      "и на воздухѣ. – Садилъ кусты и цвѣты. Получилъ\n",
      "письмо отъ Дмоховского, который вызываетъ меня\n",
      "въ Петербургъ по подряду. –\n",
      "10е. СъХлопоты по торгамъ на издѣлія отъ\n",
      "Варшавской дороги. Свиданіе съ Огаревымъ –\n",
      "11е. 12е. 13е. 14е. Въ Петербургѣ. Холодъ\n",
      "страшный. Снѣгъ и дождь. Морозитъ и таетъ. Вотъ Сторонка!!!\n",
      "16го. Выѣхалъ обратно въ Москву.\n",
      "17го. Рѣшеніе дѣла въ Уг. пал. Холодно. – Сирень\n",
      "отцвѣла.\n",
      "18е. Поѣздка съ Anais въ Воскресенское. Сирень\n",
      "отцвѣтаетъ. Начали сажать картофель – погода\n",
      "исправилась.\n",
      "22е. Вѣсь день ходилъ. Купался, вода свѣжа.\n",
      "Чувствовалъ себя хорошо. Легъ въ 11 часовъ.\n",
      "23. Всталъ въ 6-ть часовъ. Садили картофель.\n",
      "Anais устроила гостиную. Чувствовалъ себя\n",
      "хорошо – работалъ около лиственницъ.\n",
      "1855. Май\n",
      "Выѣхалъ обратно въ Москву въ шарабанѣ ночью –\n",
      "ночь свѣжая.\n",
      "24. Въ Москвѣ для полученія отсрочки отъ\n",
      "Генералъ Губерн. для прожитія въ деревнѣ. –\n",
      "Утро у Генер. Губернатора. Общій разговоръ.\n",
      "Слухи о взятіи Керчи и сожженіи Бердян\n",
      "ска. Разсказы о злоупотребленіяхъ и кражахъ въ\n",
      "Россіи, о недостаткахъ пороха и снарядовъ, пу-\n",
      "бличныя восклицанія. Адъютантъ Генер. Губерн.\n",
      "Незабвеный – его долго не забудутъ.\n",
      "25. Отравился обратно. Торопился въ Воскре-\n",
      "сенское.\n",
      "26. Хлопоты въ домѣ.\n",
      "27. Въ полдень пріѣхали ко мнѣ Шум-\n",
      "скій и Н.М. Ѳеоктистовъ.\n",
      "28. Гости: Коршъ, стар. Ѳеоктистовъ, Лох-\n",
      "вицкій, Шумскій, Мл. Ѳеоктистовъ. –\n",
      "Гуляли, ходили въ Пучьковскій лѣсъ и тамъ\n",
      "завтракали, – въ 2 часа читалъ имъ\n",
      "мою піэссу Свадьба Кречинского- успѣхъ!\n",
      "Шумскій проситъ её себѣ на бенефисъ. Вечеромъ\n",
      "всѣ уѣхали, и я остался съ Енюшкой.\n",
      "29. 30. Дни прекрасные теплые. Рожь начинаетъ\n",
      "ямою, гдѣ горѣлъ навозъ. Вечеромъ уѣхалъ съ\n",
      "Іюнь 1. Отдалъ піэссу Шумскому – и пошли въ ходъ.\n",
      "2. 3. Въ Москвѣ. Выѣхалъ въ Воскресенское.\n",
      "Время жаркое. Вечеръ удивительно теплый, полный\n",
      "благоуханій - соловей поетъ безъ умолку. Вѣсь\n",
      "день былъ занятъ въ полѣ.\n",
      "4.\n",
      "день жаркій – вечеръ совершенно тёплый.\n",
      "9. Сначала день жаркій, потомъ гроза и дождь.\n",
      "Убрано первое сѣно: клеверъ. Оный высохъ\n",
      "въ два дня. Рѣдкій случай въ нашемъ\n",
      "сѣверномъ хозяйствѣ. Вечеръ довольно свѣжъ.\n",
      "Воздушные жасмины отцвѣтаютъ. Нѣсколько\n",
      "дней начала поспѣвать клубника.\n",
      "11. Опять небо очистилось. Жарко. Занялся въ\n",
      "первый разъ и написалъ начало введенія\n",
      "къ переводу. An. уѣхала въ Москву. – .\n",
      "12. Западный вѣтеръ. Получилъ письмо\n",
      "отъ Маменьки изъ Тамбова, что тамъ\n",
      "засуха и что червь началъ ѣсть хлѣбъ\n",
      "и траву. – . Можетъ быть бѣдствіе. – .\n",
      "13. 14. Сумрачно – занимался окончательно\n",
      "Комедіей – .\n",
      "15. 16. Въ Москвѣ. Чтеніе Комедіи и\n",
      "обѣдъ, на которомъ были: Шумскій, Лен-\n",
      "скій, Садовскій, Потуловъ и Оберъ.\n",
      "Комедія понравилась.\n",
      "17. Гроза – и всё время грозы и дожди.\n",
      "18. Гроза – я кончилъ Комедію и отдалъ ее\n",
      "Шумскому. Получилъ письмо отъ N.N. о затрудненіяхъ въ\n",
      "Парижѣ относительно L.G.\n",
      "19. Утро, дождь. Выѣздъ въ Воскресенское.\n",
      "Ссора съ An. у Калужскихъ воротъ –\n",
      "примиреніе – мы отправились и прибыли\n",
      "въ Воскресенское въ 5 часовъ. Вечеръ\n",
      "хорошъ. Покосъ остановился. Навозъ продолжаютъ\n",
      "возить и уже занавозили 12ть десятинъ.\n",
      "Клубника во всёмъ развалѣ. Малина, смородина\n",
      "и вишня начинаютъ поспѣвать. Рожь\n",
      "желтѣетъ – овсы выкашиваются, но\n",
      "плохи, мелкіе и отъ жаровъ задержались.\n",
      "21. 22е. Вѣтеръ сѣверный. Во вѣсь день\n",
      "мгла во всей окрестности: синій туманъ\n",
      "1855. Iюнь.\n",
      "23. Такъ же туманъ – и еще сильнѣе – мгла\n",
      "совершенная. Съ Самсономъ ходили вездѣ – ѣздили\n",
      "въ лѣсъ. Послѣ обѣда въ 7 часовъ онъ уѣхалъ. –\n",
      "Разговоръ о военныхъ дѣйствіяхъ въ Крыму:\n",
      "для союзныхъ войскъ будущее темно и\n",
      "неблагопріятно. – Вишня и малина поспѣли.\n",
      "Клеверъ въ полномъ цвѣту и даже нѣсколько\n",
      "отцвѣтаетъ.\n",
      "24. Работалъ утромъ – окапывалъ лиственницы\n",
      "передъ домомъ. День ясный, похолодало. Вечеръ\n",
      "свѣжій – гуляли съ Anais. Переводилъ немного.\n",
      "25. Работалъ то же. Переводъ побольше. Гроза\n",
      "и проливной дождь съ вихремъ. Послѣ\n",
      "грозы купался – вода свѣжа. – . Anais тоже купалась.\n",
      "27. Поутру уѣхали въ Москву. – День средственный. –\n",
      "An. довольно хорошо. – . Гроза и дождь.\n",
      "28. Покупалъ бумагу для дома Воскресенскаго у Дабо.\n",
      "29. Петровъ день. Утромъ пріѣхали въ Воскресенское.\n",
      "Нуждаемся въ патокѣ – ибо заводъ, пущенный только\n",
      "съ 27 апрѣля, еще оной не довольно наварилъ.\n",
      "По сдѣланному счету наличность денегъ и патоки\n",
      "такая. Въ кассѣ …. 600 р. сер.         ...600\n",
      "Въ Москвѣ: по счетамъ поставлено\n",
      "товару на сумму 3020               … 3020\n",
      "за лавкою – – 943                 … 943\n",
      "Въ Воскресъ: патоки 590 п. по 1,50   … 885\n",
      "муки 3113 пуд. – патоки 3000 п. по 1,50 …. 4500\n",
      "Всего слѣдуетъ получить … 9948 р. сер.\n",
      "Уплат. по соображенію:\n",
      "въ Степ. до 1000 р. сер.\n",
      "Новосильцевой % 450.\n",
      "по счетамъ 300.\n",
      "До 7 т.р. сер. должно остаться на слѣдующій\n",
      "годъ для обороту.\n",
      "Послалъ положить въ ломбардъ 250 въ первый\n",
      "разъ въ моей жизни – мнѣ теперь 37 лѣтъ и 9 мѣсяцевъ.\n",
      "1855. Іюль.\n",
      "1е іюля. Работалъ около лиственницъ, но не\n",
      "много. Купался два раза – вода свѣжа.\n",
      "4е. Всталъ слабъ. Пріѣхалъ архитекторъ\n",
      "Герасимовъ, которому заказалъ рисунокъ\n",
      "ограды предъ домомъ, колонны, вазъ на\n",
      "ограду и въѣздныхъ воротъ.\n",
      "5-е. Всталъ не рано, только расположился по дѣлу\n",
      "въ 11 ч. пріѣхалъ Чернявскій съ сыномъ –\n",
      "по отъѣздѣ ихъ гулялъ одинъ – былъ въ\n",
      "грустномъ расположеніи духа.\n",
      "1855. Iюль.\n",
      "въ 8м часу вечера. – .\n",
      "7е. Начали жать рожь.\n",
      "8е. Пріѣхалъ въ Москву. – . Сборъ въ Степную.\n",
      "9. 10. 11. 12. Въ Москвѣ хлопоты по\n",
      "дѣламъ Anais – договоръ съ адвока-\n",
      "томъ Кольрейфомъ. Подписано условіе.\n",
      "13е и 14е. Окончаніе дѣла. Выѣхали\n",
      "въ Воскресенское. Рожь сжата, роди-\n",
      "лась по 22 копны на десятинѣ.\n",
      "16е. У Закревскихъ вѣсь день.\n",
      "18е. Выѣхалъ въ Москву за отпускомъ.\n",
      "19. 20. 21. 22. Въ Москвѣ.\n",
      "23. Пріѣхали въ Воскресенское въ\n",
      "брэке. –.\n",
      "24. У князя Четверт. на именинахъ.\n",
      "Поздно вечеромъ вернулся домой. An. встрѣтила\n",
      "меня по дорогѣ – ночь удивительная.\n",
      "Всё это время: сонъ хорошъ – я пополнѣлъ, но\n",
      "равновѣсія мало – нѣсколько тягости въ тѣлѣ.\n",
      "Не работаю ни физически, ни умственно.\n",
      "Рецептъ отъ холеры. Взять масла коноплянаго\n",
      "изъ неспѣлой конопли самаго душистаго\n",
      "двѣ части – и одну часть чистаго дегтя\n",
      "и дать выпить рюмку – и давать пить\n",
      "мятнаго чаю. – .\n",
      "25-е число іюля. Всталъ не рано, утромъ отправился на\n",
      "покосъ на Солдатъ. сѣчу – возвратился и едва отдалъ лошадь,\n",
      "какъ распространился слухъ, что два человѣка зарублены\n",
      "разбойникомъ у Кирпичнаго завода. Общая суматоха. – Дѣйстви-\n",
      "тельно, неизвѣстный человѣкъ, вѣроятно бѣглый солдатъ\n",
      "зарубилъ топоромъ крестьянина Самсона, жену его Маремьяну\n",
      "ранилъ третьяго и, преслѣдуемый людьми, самъ уто-\n",
      "пился въ рѣкѣ. Разсылы, разспросы и хлопоты.\n",
      "26-е. Пріѣхалъ становой и собраны понятые для\n",
      "слѣдствія.\n",
      "27-е. Было временное слѣдствіе. Къ вечеру я чувство-\n",
      "1855. Iюль и Августъ.\n",
      "29. Поѣхалъ въ Москву въ стедже съ An.\n",
      "30. 31. Нездоровъ. Получилъ изъ Цензуры возвра-\n",
      "щенную для поправокъ піэссу. – Занимался\n",
      "съ Шумскимъ.\n",
      "Августъ 1е. Пріѣхалъ изъ Петербурга Сорочинскій, привезъ\n",
      "извѣстіе о бомбордированіи Свеаборга. Вечеръ\n",
      "у меня Сорочъ. и Шумскій. Сергѣй Ивановичъ Тол-\n",
      "бузинъ умеръ у меня во флигелѣ – при-\n",
      "сутствовалъ при его послѣднихъ минутахъ –\n",
      "очень разстроенъ.\n",
      "2. 3. 4. Не совсѣмъ здоровъ, разстроенъ, скученъ –\n",
      "сильная хандра.\n",
      "5е. Погребеніе старика Толбузина. Проводилъ\n",
      "его до кладбища.\n",
      "6е. Выѣздъ въ Петербургъ. Ѣхалъ съ Шульцемъ –\n",
      "тоска и хандра.\n",
      "7е. Пріѣхавши въ Петербургъ прямо къ Дмоховскому\n",
      "гдѣ, посовѣтовавшись о піэссе, тотчасъ\n",
      "началъ её исправлять. Остановился у Голицыныхъ\n",
      "на Черной рѣчкѣ на дачѣ Бахтина.\n",
      "8е. Понедѣльникъ. Свиданіе съ Цензоромъ въ 3м отдѣленіи.\n",
      "Высокій человѣкъ, худощавый – наружность походитъ\n",
      "на правителя дѣлъ у какого-нибудь большого\n",
      "барина.\n",
      "1851 годъ. Генварь. Писалъ. Ходилъ въ Гимнастику. Первое\n",
      "влiянiе было сильное, но только на мускулы, а\n",
      "не на нервы. Бесѣдовалъ сѣ Кноррин.\n",
      "Апрѣль. Слѣдствие кончилось; въ среду на святой выѣхалъ\n",
      "въ Новое по страшной грязи и распутицѣ.\n",
      "Май. Выѣхалъ въ Петербургъ. 12гo прибылъ туда,\n",
      "писалъ письмо и записку къ Государю. Голицына и\n",
      "Laliky. Поѣздка на острова. Въ iюнѣ прiѣхалъ\n",
      "Сальясъ. Поѣздка въ Красное Село, и подана просьба.\n",
      "Августъ. 23гo возвратился с Сальясомъ въ Москву, и\n",
      "проѣхаливмѣстѣ на Выксу. Осенью началъ первую\n",
      "перестройку дома. Октябрь. Уѣхалъ съ Сальясомъ\n",
      "въ Расву. 2 мѣсяца въ Расвѣ. Дѣло в Палатѣ. Декабрь.\n",
      "1852. Рождество у дяди. Болѣзнь Прасковьи Александровны.\n",
      "Соня уѣхала въ Крым. - Смерть Прасковьи Александровны.\n",
      "Святую провелъ въ Тихоновой пустыни съ дядей. Лѣто про-\n",
      "велъ въ Москве. Дѣло поступило въ Сенатъ. Мое руко-\n",
      "прикладство и начало правильнаго купанья. Въ августѣ\n",
      "уѣхалъ въ Петербургъ. Горѣловская охота. Laliky. Сентябрь.\n",
      "17 числа прiѣхалъ съ Потемкинымъ въ Москву. На лодкѣ\n",
      "простудился. Октябрь. Горячка. Ноябрь и декабрь. Петер-\n",
      "1853. бургъ. Laliky. Захоржевская. Генварь, февраль, мартъ на Выксѣ\n",
      "Писалъ ответъ въ М. Ф-овъ и пьессу. Святая у дяди въ\n",
      "Калугѣ 3 дня. Поѣхалъ въ Алексѣевское. Покупка Воейковскаго\n",
      "имѣнiя. Лукьяновъ. Покупка Захлебовки.\n",
      "Говоритъ мягко, а безъ апелляціи. Не допускаетъ никакой\n",
      "тривіальности и потребовалъ, чтобы многое было\n",
      "перемѣнено непремѣнно, а то говоритъ: «мы положимъ\n",
      "\n",
      "\n",
      "Примеры исправлений, требующихся от тебя:\n",
      "1856. Мартъ -> 1856. Мартъ\n",
      "3-е. Въ часовъ пріѣхалъ въ Канугу. Дядѣ принялъ меня -> 3е. Въ 11 часовъ пріѣхалъ въ Калугу. Дядя принялъ меня\n",
      "лучше. Стотрѣли иланхъ моего завода – онъ далъ мнѣ -> лучше. Смотрѣли планы моего Завода – онъ далъ мнѣ\n",
      "Отдалъ перепиывать піэссу въ Печать. -> Отдалъ переписывать піэссу въ печать.\n",
      "4-е. Утро провелъ съ дядей въ разговорхъ о семейныхъ -> 4е. Утро провелъ съ дядей въ разговорахъ о семейныхъ\n",
      "дѣлахъ и о Выксѣ – послѣ обѣда выѣхалъ въ раву. -> дѣлахъ и о Выксѣ. Послѣ обѣда выѣхалъ въ Расву.\n",
      "5-е. 6-е Въ расвѣ. Перемѣна въ плань завода. 1-е. леѣьной -> 5е. 6е. Въ Расвѣ. Перемѣна въ планѣ Завода. 1е. Мѣдной\n",
      "посиуды изъ за границы не вынижеваю, выторка кой – -> посуды изъ-за границы не выписываю, выпарка пой-\n",
      "детъ живымъ огнемъ – за то Пресовую подыма -> детъ живымъ огнемъ – за симъ прессовую подымаю\n",
      "лодъ дефикадіей – и ставляю чуунный остарать. -> надъ дефекаціей и ставлю чугунный аппаратъ!\n",
      "Обѣщаю и чай ныю у Вертамъ. Гажена лм-, чалоде -> Обѣдаю и чай пью у Вермана. Его жена M-me Lattage\n",
      "прекрасная женщина и какъ транщужеска всюхить -> прекрасная женщина и какъ француженка вноситъ\n",
      "удивительную Гормонію, складъ, и какое-то -> удивительную Гармонію, складъ и какое-то\n",
      "проперное извщенство въ стйную жизнь – я мепоце. 6-го вчеромъ -> прекрасное изящество въ семейную жизнь – le menage. 6-го вечеромъ\n",
      "болтали до 1-го часа почи. Я en verve. Былъ тутъ кото- -> болтали до 1-го часа ночи. Я en verve. Былъ тутъ помо-\n",
      "тиникъ вертьна барельсъ женою – впостлѣніе я на, нихъ -> щникъ Вермана Каревъ съ женою – впечатлѣніе я на нихъ\n",
      "произвылъ странное – они съ такими уморительевми -> произвелъ странное – они съ такими уморительными\n",
      "поклопами провожали меня, что мнѣ Самому было -> поклонами провожали меня, что мнѣ самому было\n",
      "неловко. -> неловко.\n",
      "7-е. Выѣхалъ обратно въ Малугу. Вечеромъ вылалъ Соричася -> 7-е. Выѣхалъ обратно въ Калугу. Вечеромъ выслалъ Сорина съ\n",
      "таказами въ Заводъ. – . -> заказами въ Заводъ. –\n",
      "8е. Всталъ рано ходилъ гулять но безмодной и снѣгомъ. -> 8-е. Всталъ рано. Ходилъ гулять по безлюдной и снѣгомъ\n",
      "на чиить з апесенной Калуѣ. Занимался сверкого -> начисто занесенной Калугѣ. Занимался свѣркою\n",
      "рукопней піэссы, – перешинаю всё подлѣйтимъ образомъ– -> рукописей піэссы – переписано всё подлѣйшимъ образомъ.\n",
      "9-е. Вядя не здоровъ глазами – ему ставили піяьки. Назни - -> 9-е. Дядя нездоровъ глазами – ему ставили піявки. Назна-\n",
      "что вереромъ читать піэсса. Получены газеты. Московскія Дѣ- -> чено вечеромъ читать піэссу. Получены газеты: Московскія Вѣ-\n",
      "домости содержамъ отпсаніе угощенія Севастопольцевъ – -> домости содержатъ описаніе угощенія Cевастопольцевъ –\n",
      "Бедемертныне боги. чложе это такое. Комъ Россія разбина -> Безсмертные Боги. Что жъ это такое? Когда Россія разбита\n",
      "въ прахъ, склонила голову, когда торжествуюціи вра -> въ прахъ, склонила голову, когда торжествующій врагъ\n",
      "одною рукого размстываетъ на встеръ отованія Иевасто- -> одною рукою разметываетъ на вѣтеръ основаніе Севасто-\n",
      "шоля. Фномъ пошебъ, Черна морое отнято, крѣпоти обо- -> поля – флотъ погибъ, Черное море отнято, крѣпости: ото-\n",
      "браны, когда Улиссу дернаютъ дубы и затавляютъ нау- -> браны, когда Улиссу держатъ зубы и заставляютъ под-\n",
      "писывать отрѣшеніе отъ всѣхъ пралъ и отольтнихъ ровое – -> писывать отреченіе отъ всѣхъ правъ и столѣтнихъ завое-\n",
      "в ваній – Отрыніе отъ флота, отъ Востьска, отъ ликоловва, -> ваній – Отреченіе отъ флота, отъ Востока, отъ Николаева,\n",
      "Защитниковъ взятаю сѣвастополъ причимаютъ какъ побзители -> защитниковъ взятаго Севастополя принимаютъ какъ побѣдителей.\n",
      "кого?. когда гдв. Ут сальмѣ, подъ Черной. При Иикресенѣ: иѣ -> Кого? Когда? Гдѣ? При Альмѣ, подъ Черной? При Иккермане? Или\n",
      "въ Гамомъ Сватнополѣ!. . Мое жинымъ въ такія, дременни -> въ самомъ Севастополѣ?... Мы живемъ въ такіе времена,\n",
      "когда всякое чувство достотива и личнаго и каудпаль- -> когда всякое чувство достоинства, и личнаго и національ-\n",
      "наю, должно закрыстъ себѣ лице рукоми, чтобы не -> наго, должно закрыть себѣ лицо руками чтобы не\n",
      "видѣть и свѣта божія. Гольшой разговоръ тъ дядей и -> видѣть и свѣта Божія. Большой разговоръ съ дядей и\n",
      "бексеромъ о Мословскихъ дашахъ, говоривтикъ рѣчи -> Беккеромъ о Московскихъ дамахъ, говорившихъ рѣчи\n",
      "1856. Март -> 1856. Мартъ\n",
      "и онатріюнизмѣ эткупзика Кокарева. Ѳеобливо прого -> и о патріотизмѣ откупщика Кокорева. Особливо трога-\n",
      "теленъ ео Замной поклонъ сѣвастополескимѣ мо- -> теленъ его земной поклонъ севастопольскимъ мо-\n",
      "Рякамъ. По этомъ случаго я замѣтилъ, что вовсѣ -> рякамъ. По этому случаю я замѣтилъ, что во всѣхъ\n",
      "подобныхъ опказіяхъ Откумзнкги болѣе прошелъ -> подобныхъ оказіяхъ Откупщики болѣе прочихъ\n",
      "отличаются у насъ на руги Самыми живрими -> отличаются у насъ на Руси самыми живыми\n",
      "у ствами натрію низема – Обобралъ крещеный на- -> чувствами патріотизма – обобравъ крещеный на-\n",
      "родъ, и составиьши, мнлѣюпы ище. Грошей протитвія -> родъ и составивши милліоны изъ Грошей, пропитыхъ\n",
      "именно тѣеніи у когю этомъ громъ послѣдный, пусти- -> именно теми, у кого этотъ Грошъ послѣдній, пусти-\n",
      "вни по міру цѣлыя области, они вечеда изглвлять -> вши по міру цѣлые области, они всегда изъявляютъ\n",
      "особенную готовноть пожутровать нѣсколько тыня -> особенную готовность пожертвовать нѣсколько тысячъ\n",
      "рублій для бѣдныхъ, на преюты дѣшей просивтит -> рублей для бѣдныхъ, на пріюты дѣтей пропившихся\n",
      "обывателей и вообще, на свсѣ патроо пическія дѣя -> обывателей и вообще на всё патріотическіе цѣли,\n",
      "не ходянщіясъ съ распоряженія правителъ таи – траю- -> находящіеся въ распоряженіи правительства, – трога-\n",
      "тельное зрѣлице) Никогда не прохожу я мичг -> тельное зрѣлище! Никогда не прохожу я мимо\n",
      "зергольныхъ оконъ и тресъ этожныхъ палатя опкун- -> зеркальныхъ оконъ и трехъэтажныхъ палатъ откуп-\n",
      "щикахъ Реюмина, Конилева. Боробина, Воронова, -> щиковъ Рюмина, Кошелева, Бородина, Воронова\n",
      "пор. Ечтобы не подивится, какъ изъ малаго роставлей -> и др. чтобы не подивиться, какъ изъ малаго составля-\n",
      "ети большое, и не размыстить сколько должно -> ется большое, и не размыслить, сколько должно\n",
      "было протиныся и отитвія мужиковъ, чтоба эт -> было пропиться и отпиться мужиковъ, чтобы эти\n",
      "кварты и гарки соволупясь вмѣстѣ сожтавили эти -> кварты и чарки, совокупя вмѣстѣ, составили эти\n",
      "палаты, сколько просито и занито дорованій, спосо- -> палаты, – сколько пропито и запито дарованій, спосо-\n",
      "бносшей, доровля, силъ, сколько кочерекаю, или ослобнено -> бностей, здоровья, силъ, – сколько кочергою или оглоблею\n",
      "бить женъ, неветокъ и всей сфапиліи, чтобыэти -> бито жёнъ, невестокъ и всей фамиліи, чтобы эти\n",
      "натріюзмомъ, проникнутые свены отечетла, подѣтжни -> патріотизмомъ проникнутые Сыны отечества, подъѣзжая\n",
      "на парѣ сѣрыхъ къ дому Градопачальниковъ его -> на парѣ гнѣдыхъ къ дому Градоначальниковъ, по\n",
      "движенню ихъ серцедь прешели на картопный и -> движенію ихъ сердецъ, приносили на картонный и\n",
      "стирновымъ отемъ горящій остарь отепенсло свои -> спиртовымъ огнемъ Горящій алтарь отечества свои\n",
      "пожиррованія ъ двѣтущія, на ихъ толитыехъ и жизныхъ -> пожертвованія, цвѣтущіе на ихъ толстыхъ и жирныхъ\n",
      "тяхъ всякаго рода крестелькими и зеленискоми, -> шеяхъ всякаго рода красненькими и зелененькими\n",
      "лектолѣками. -> ленточками.\n",
      "но поводу земинаю поклопа чувствительнаго Кокорова -> По поводу земнаго поклона чувствительнаго Кокорева\n",
      "беккеръ разказывалъ: Когда въ Калугу водомо было тѣло -> Беккеръ разсказывалъ: когда въ Калугу везомо было тѣло\n",
      "покойной государыти сииветы Алекыевны изъ бслева) всё -> покойной государыни Еливеты Алексѣевны (изъ Белева), всё\n",
      "Калужско. Купесетво – вышло на крутую гору оки -> Калужское купечество – вышло на Крутую гору Оки\n",
      "встрѣать опое – процессія была большая и кн. Волхон -> встрѣчать оное – процессія была большая, и кн. Волкон-\n",
      "скій оного распоряжился. Лишь показались зарѣкого -> скій оною распоряжался. Лишь показалась за рѣкою\n",
      "процессія – полова Канур. Кртченва. Купецъ Бюзнилъ -> процессія – голова калуж. купечества купецъ Зюзинъ\n",
      "обратился къ Пошцій мистру съ встрогомъ: то купече -> обратился къ полицеймейстеру съ вопросомъ: что купече-\n",
      "тиво желало бы стать на колѣна, и потому -> ство желало бы стать на колѣни, и потому\n",
      "будетъ ли это разрѣшено лачильствомъ. – Востый Ман- -> будетъ ли это разрѣшено Начальствомъ. – Василій Ман-\n",
      "даринъ бывшіи Полизъ мейсторомъ немогъ розрѣпить -> доринъ, бывшій nолицеймейстеромъ, не могъ разрѣшить\n",
      "по долгу служды -> по долгу службы\n",
      "этого обстоятельета, и обратился къ Губрнатору – -> этого обстоятельства и по долгу службы обратился къ Губернатору –\n",
      "сей также – ивоторосъ дошелъ взъ самаю Кн. Вол- -> сей также – и вотъ онъ дошелъ до самого кн. Вол-\n",
      "хоискаго и хотъ въ растяжку., былъ корошскій отѣтъ -> конского. «Хоть въ раскорячку», былъ короткій отвѣтъ.\n",
      "было Странная Грядвъ и купечетву показалось -> Была страшная грязь, и купечеству показалось\n",
      "запруднительнымъ лѣжать брігхомъ и беродою -> затруднительнымъ лежать брюхомъ и бородою\n",
      "въ рязи особлинъ, долго времся. Получилъ отвѣтъ -> въ грязи особливо долгое время. Получивъ отвѣтъ,\n",
      "Купезы споличнисковали и оденъ поодному разошли -> купцы сполитиковали и одинъ по одному разошлись\n",
      "въ ъ парадъ – и бо лежаніе въ Грязи, стало для -> въ пу народъ – ибо лежаніе въ грязи стало для\n",
      "нихъ какъ бы обящательнымъ – чѣту удиолятвъ -> нихъ какъ бы обязательнымъ. – Чему удивляться\n",
      "сердицъ -> Сердецъ\n",
      "болѣе – этимъ ли движеніямъ чердца вечеда повишую – -> болѣе – этимъ ли движеніямъ сердца всегда навстрѣчу –\n",
      "1856 год. мартъ -> 1856. годъ. Мартъ\n",
      "венеца такъ вѣрно и такъ откравенно оцѣнивнющей -> всегда такъ вѣрно и такъ откровенно оцѣнивающему\n",
      "эти натріитинскія движенія. -> эти патріотическія движенія.\n",
      "Поводу разговоръ о пришеднемъ векаефъ расказы -> Поводу разговоровъ о прошедшемъ Беккеръ разсказы-\n",
      "валъ. Въ проѣздъ к. Н. Грезъ кануху онъ пообачаю посѣ- -> валъ. Въ проѣздъ К. П. чрезъ Калугу онъ по обычаю посѣ-\n",
      "талъ исктоительно большу и острочъ. Въ послѣдненъ -> тилъ исключительно больницу и острогъ. Въ послѣднемъ\n",
      "занялся разстановкою часоввю въ заніе остроги - -> занялся разстановкою часовыхъ въ зданіи острога –\n",
      "этитъ еѣда. Этоо здыв. Ты туть ни доялевре на -> Этотъ сюда! Этого здѣсь! Ты тутъ! Ты далѣе – всё навыворотъ.\n",
      "когди одиныизъ этилъ, часовыхъ былъ нять съ окед -> Когда одинъ изъ этихъ часовыхъ былъ снятъ съ очень\n",
      "лужнаго поста тоемъ замѣчено было, что самы -> нужнаго поста, то ему замѣчено было, что самые\n",
      "претзные изъ арестантовъ не будутъ въ призорѣ -> преступные изъ арестантовъ не будутъ въ призорѣ\n",
      "и могутъ выскочитъ въ Коридоръ – пу – иснѣскомъ -> и могутъ выскочить въ корридоръ. – Ну – штыкомъ\n",
      "его!.. ОВъ одной каторѣ содержался сфицеръ -> его!… Въ одной камерѣ содержался офицеръ –\n",
      "онъ подотилъ къ нему и прочилъ, что уже три года -> онъ подошелъ къ нему и просилъ, что уже три года\n",
      "содержится безъ веты и никого рѣшетія нѣтъ. Разс- -> содержится безъ вины и никакого рѣшенія нѣтъ. Раз\n",
      "берутъ? – быно отвѣтомъ. Просителъ объяжнилъ, что -> берутъ! – было отвѣтомъ. Проситель объяснилъ, что\n",
      "онъ раслаетъ погоритыя всяскому рѣшенію лист -> онъ согласенъ покориться всякому рѣшенію, лишь\n",
      "бы видѣть какойлибо конецъ сфосту дѣлу. -> бы видѣть какой-либо конецъ своему дѣлу.\n",
      "Ра въ бефутъ!!..... Было отвѣтомъ – и толкко. -> Ра-зберутъ!!!... – было отвѣтомъ – и только.\n",
      "Обходя аретанскую больнцу онъ питалъ всъ -> Обходя арестантскую больницу, онъ читалъ всѣ\n",
      "«подини волѣзной – оказалась одеи детепѣга. -> подписи болѣзней – оказалось одно Demention.\n",
      "э00 что?.. Мудикъ объястилъ, что субыктъ -> Это что?!! … Медикъ объяснилъ, что субъектъ\n",
      "находится во временномъ помѣшнательствѣ, но- -> находится во временномъ помѣшательствѣ, ко-\n",
      "торое скора должно, пройши. – Отъ,ч -> торое скоро должно пройти – Отъ чего?!..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = make_system_prompt_v2(eval_val[\"str_gt\"], eval_val[\"str_preds\"], eval_train[\"str_gt\"], eval_train[\"str_preds\"])\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def get_correction_v3(\n",
    "    model_lines,\n",
    "    sleep_seconds=10,\n",
    "    n_tries=4,\n",
    "    **get_response_kwargs\n",
    "):\n",
    "    corrected_lines = []\n",
    "    conversation_history = None\n",
    "    for model_line in tqdm(model_lines):\n",
    "        for try_n in range(n_tries):\n",
    "            corrected_line, conversation_history = get_response_v2(\n",
    "                model_line + \" -> \", conversation_history, **get_response_kwargs\n",
    "            )\n",
    "            if corrected_line is not None:\n",
    "                corrected_lines.append(corrected_line)\n",
    "                break\n",
    "            elif try_n == n_tries - 1:\n",
    "                # last try faliled\n",
    "                raise Exception(f\"Could not get response for {model_line}\")\n",
    "            else:\n",
    "                time.sleep(sleep_seconds)\n",
    "\n",
    "    return corrected_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/74 [01:09<13:48, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 7.669096946s. Reset after: 44.64349696s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 7.669096946s. Reset after: 44.64349696s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 7.669096946, 'reset_after': 44.64349696}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/74 [01:28<16:16, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.777301937s. Reset after: 48.672501951s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.777301937s. Reset after: 48.672501951s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 11.777301937, 'reset_after': 48.672501951}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.636902928s. Reset after: 38.532102942s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.636902928s. Reset after: 38.532102942s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.636902928, 'reset_after': 38.532102942}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 8/74 [02:24<23:08, 21.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.429762929s. Reset after: 38.216962933s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.429762929s. Reset after: 38.216962933s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.429762929, 'reset_after': 38.216962933}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 10/74 [02:59<19:24, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 13.677297919s. Reset after: 50.360097914s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 13.677297919s. Reset after: 50.360097914s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 13.677297919, 'reset_after': 50.360097914}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.452290922s. Reset after: 40.135090917s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.452290922s. Reset after: 40.135090917s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 3.452290922, 'reset_after': 40.135090917}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 13/74 [04:08<18:00, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.977060914s. Reset after: 51.484660923s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.977060914s. Reset after: 51.484660923s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 14.977060913999999, 'reset_after': 51.484660923}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.781766921s. Reset after: 41.28936693s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.781766921s. Reset after: 41.28936693s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 4.781766921, 'reset_after': 41.28936693}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 15/74 [04:49<17:08, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 21.371682912s. Reset after: 57.717282921s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 21.371682912s. Reset after: 57.717282921s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 21.371682912, 'reset_after': 57.717282921}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.227381914s. Reset after: 47.572981923s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.227381914s. Reset after: 47.572981923s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 11.227381914, 'reset_after': 47.572981923}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.083978891s. Reset after: 37.4295789s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.083978891s. Reset after: 37.4295789s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.083978891, 'reset_after': 37.4295789}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 16/74 [05:21<21:17, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 12.38725692s. Reset after: 48.671656906s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 12.38725692s. Reset after: 48.671656906s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 12.38725692, 'reset_after': 48.671656906}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 2.17889893s. Reset after: 38.463298916s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 2.17889893s. Reset after: 38.463298916s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 2.17889893, 'reset_after': 38.463298916}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 17/74 [05:43<20:56, 22.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.071947902s. Reset after: 50.290347903s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.071947902s. Reset after: 50.290347903s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 14.071947902, 'reset_after': 50.290347903}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.83316493s. Reset after: 40.051564931s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.83316493s. Reset after: 40.051564931s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 3.83316493, 'reset_after': 40.051564931}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 18/74 [06:20<24:33, 26.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.650934934s. Reset after: 37.79973492s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.650934934s. Reset after: 37.79973492s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.650934934, 'reset_after': 37.79973492}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 20/74 [06:50<17:27, 19.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 19.665867924s. Reset after: 55.691067934s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 19.665867924s. Reset after: 55.691067934s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 19.665867924, 'reset_after': 55.691067934}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 9.489642918s. Reset after: 45.514842927s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 9.489642918s. Reset after: 45.514842927s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 9.489642918, 'reset_after': 45.514842927}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 21/74 [07:12<18:00, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 20.945535928s. Reset after: 56.915535926s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 20.945535928s. Reset after: 56.915535926s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 20.945535927999998, 'reset_after': 56.915535926}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 10.732539921s. Reset after: 46.70253992s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 10.732539921s. Reset after: 46.70253992s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 10.732539921, 'reset_after': 46.70253992}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 529.092937ms. Reset after: 36.499092936s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 529.092937ms. Reset after: 36.499092936s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 0.529092937, 'reset_after': 36.499092936}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 22/74 [07:46<21:00, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.802879929s. Reset after: 47.711679935s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.802879929s. Reset after: 47.711679935s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 11.802879929, 'reset_after': 47.711679935}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.630223929s. Reset after: 37.539023935s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.630223929s. Reset after: 37.539023935s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.630223929, 'reset_after': 37.539023935}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 23/74 [08:15<21:55, 25.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.516055911s. Reset after: 42.361255913s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.516055911s. Reset after: 42.361255913s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 6.5160559110000005, 'reset_after': 42.361255913}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 24/74 [08:28<18:10, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.252374947s. Reset after: 54.027974933s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.252374947s. Reset after: 54.027974933s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 18.252374947, 'reset_after': 54.027974933}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.026050925s. Reset after: 43.801650911s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.026050925s. Reset after: 43.801650911s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 8.026050925, 'reset_after': 43.801650911}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 25/74 [09:05<21:44, 26.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.729339957s. Reset after: 40.440139949s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.729339957s. Reset after: 40.440139949s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 4.729339957, 'reset_after': 40.440139949}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 26/74 [09:17<17:47, 22.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 17.084463953s. Reset after: 52.746063947s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 17.084463953s. Reset after: 52.746063947s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 17.084463953, 'reset_after': 52.746063947}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.940787941s. Reset after: 42.602387934s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.940787941s. Reset after: 42.602387934s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 6.940787941, 'reset_after': 42.602387934}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 27/74 [09:51<20:03, 25.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 7.99111697s. Reset after: 43.599916964s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 7.99111697s. Reset after: 43.599916964s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 7.99111697, 'reset_after': 43.599916964}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 28/74 [10:12<18:39, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 10.993155956s. Reset after: 46.543155968s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 10.993155956s. Reset after: 46.543155968s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 10.993155956, 'reset_after': 46.543155968}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 791.502952ms. Reset after: 36.341502964s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 791.502952ms. Reset after: 36.341502964s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 0.791502952, 'reset_after': 36.341502964}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 29/74 [10:36<18:07, 24.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.802003949s. Reset after: 47.286003947s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.802003949s. Reset after: 47.286003947s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 11.802003949, 'reset_after': 47.286003947}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.590085953s. Reset after: 37.07408595s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.590085953s. Reset after: 37.07408595s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.590085953, 'reset_after': 37.07408595}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 31/74 [11:15<14:28, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 22.065224945s. Reset after: 57.406424939s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 22.065224945s. Reset after: 57.406424939s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 22.065224945, 'reset_after': 57.406424939}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.851178944s. Reset after: 47.192378938s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 11.851178944s. Reset after: 47.192378938s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 11.851178944, 'reset_after': 47.192378938}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.637575954s. Reset after: 36.978775948s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.637575954s. Reset after: 36.978775948s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.637575954, 'reset_after': 36.978775948}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 32/74 [11:48<16:47, 24.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 13.932472974s. Reset after: 49.206472963s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 13.932472974s. Reset after: 49.206472963s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 13.932472974, 'reset_after': 49.206472963}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.713688969s. Reset after: 38.987688958s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.713688969s. Reset after: 38.987688958s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 3.713688969, 'reset_after': 38.987688958}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 33/74 [12:26<19:23, 28.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 123.372972ms. Reset after: 35.320572972s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 123.372972ms. Reset after: 35.320572972s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 0.123372972, 'reset_after': 35.320572972}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 34/74 [12:39<15:44, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 12.501993983s. Reset after: 47.624793976s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 12.501993983s. Reset after: 47.624793976s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 12.501993983, 'reset_after': 47.624793976}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 2.343147963s. Reset after: 37.465947955s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 2.343147963s. Reset after: 37.465947955s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 2.343147963, 'reset_after': 37.465947955}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 35/74 [13:12<17:16, 26.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.003279983s. Reset after: 39.062479972s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.003279983s. Reset after: 39.062479972s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 4.003279983, 'reset_after': 39.062479972}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 36/74 [13:25<14:09, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 16.482048988s. Reset after: 51.472848981s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 16.482048988s. Reset after: 51.472848981s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 16.482048988, 'reset_after': 51.472848981}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.267730981s. Reset after: 41.258530974s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.267730981s. Reset after: 41.258530974s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 6.267730981, 'reset_after': 41.258530974}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 37/74 [13:48<13:50, 22.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.85898298s. Reset after: 53.776582986s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.85898298s. Reset after: 53.776582986s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 18.85898298, 'reset_after': 53.776582986}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.63588497s. Reset after: 43.553484976s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.63588497s. Reset after: 43.553484976s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 8.63588497, 'reset_after': 43.553484976}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 38/74 [14:27<16:33, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.405401974s. Reset after: 39.252201974s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 4.405401974s. Reset after: 39.252201974s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 4.405401974, 'reset_after': 39.252201974}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 39/74 [14:55<16:10, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.620968967s. Reset after: 36.398168981s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 1.620968967s. Reset after: 36.398168981s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 1.620968967, 'reset_after': 36.398168981}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 40/74 [15:16<14:34, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 5.916457951s. Reset after: 40.619257956s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 5.916457951s. Reset after: 40.619257956s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 5.916457951, 'reset_after': 40.619257956}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 41/74 [15:29<12:00, 21.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.584781974s. Reset after: 53.217981964s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.584781974s. Reset after: 53.217981964s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 18.584781974, 'reset_after': 53.217981964}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.437157988s. Reset after: 43.070357978s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.437157988s. Reset after: 43.070357978s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 8.437157988, 'reset_after': 43.070357978}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 42/74 [16:07<14:14, 26.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 5.844353973s. Reset after: 40.393553972s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 5.844353973s. Reset after: 40.393553972s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 5.8443539730000005, 'reset_after': 40.393553972}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 43/74 [16:35<13:57, 27.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.705147951s. Reset after: 38.161947965s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.705147951s. Reset after: 38.161947965s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 3.705147951, 'reset_after': 38.161947965}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 44/74 [16:48<11:24, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 16.262204945s. Reset after: 50.629004955s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 16.262204945s. Reset after: 50.629004955s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 16.262204945, 'reset_after': 50.629004955}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.052192956s. Reset after: 40.418992966s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.052192956s. Reset after: 40.418992966s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 6.052192956, 'reset_after': 40.418992966}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 45/74 [17:16<11:46, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.040018945s. Reset after: 48.328818947s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.040018945s. Reset after: 48.328818947s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 14.040018945, 'reset_after': 48.328818947}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.835949957s. Reset after: 38.124749958s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.835949957s. Reset after: 38.124749958s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 3.835949957, 'reset_after': 38.124749958}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 46/74 [17:40<11:23, 24.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 15.378424972s. Reset after: 49.601224958s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 15.378424972s. Reset after: 49.601224958s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 15.378424972, 'reset_after': 49.601224958}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 5.221947968s. Reset after: 39.444747954s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 5.221947968s. Reset after: 39.444747954s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 5.221947968, 'reset_after': 39.444747954}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 47/74 [18:02<10:39, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 19.133031964s. Reset after: 53.291031956s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 19.133031964s. Reset after: 53.291031956s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 19.133031964, 'reset_after': 53.291031956}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.980171978s. Reset after: 43.13817197s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.980171978s. Reset after: 43.13817197s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 8.980171978, 'reset_after': 43.13817197}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 48/74 [18:31<10:54, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 16.442623972s. Reset after: 50.525023967s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 16.442623972s. Reset after: 50.525023967s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 16.442623972, 'reset_after': 50.525023967}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.209533989s. Reset after: 40.291933983s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 6.209533989s. Reset after: 40.291933983s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 6.209533989, 'reset_after': 40.291933983}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 49/74 [18:54<10:15, 24.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.998510986s. Reset after: 53.006510972s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 18.998510986s. Reset after: 53.006510972s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 18.998510986, 'reset_after': 53.006510972}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.769850999s. Reset after: 42.777850985s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 8.769850999s. Reset after: 42.777850985s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 8.769850998999999, 'reset_after': 42.777850985}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 50/74 [19:30<11:14, 28.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 9.013877004s. Reset after: 42.945077002s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 9.013877004s. Reset after: 42.945077002s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 9.013877004, 'reset_after': 42.945077002}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 51/74 [19:48<09:34, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 17.38796398s. Reset after: 51.238763988s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 17.38796398s. Reset after: 51.238763988s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 17.38796398, 'reset_after': 51.238763988}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 7.17990598s. Reset after: 41.030705988s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 7.17990598s. Reset after: 41.030705988s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 7.17990598, 'reset_after': 41.030705988}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 52/74 [20:11<08:54, 24.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 21.045262992s. Reset after: 54.814462989s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 21.045262992s. Reset after: 54.814462989s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 21.045262992, 'reset_after': 54.814462989}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 10.881921976s. Reset after: 44.651121973s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 10.881921976s. Reset after: 44.651121973s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 10.881921976, 'reset_after': 44.651121973}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 736.497998ms. Reset after: 34.505697995s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 736.497998ms. Reset after: 34.505697995s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 0.736497998, 'reset_after': 34.505697995}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 53/74 [20:44<09:25, 26.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.181484997s. Reset after: 47.870285004s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 14.181484997s. Reset after: 47.870285004s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 14.181484997, 'reset_after': 47.870285004}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n",
      "{'error': {'code': 8, 'message': \"openaiproxy.(*ServiceImplementation).processChatCompletionRequest: can't do chat completion - proxy.(*UseCase).ChatCompletion: can't check request - code: <nil>, message: proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.936334997s. Reset after: 37.625135004s., param: <nil>, type: proxy_limit_reached\", 'details': [{'@type': 'type.googleapis.com/openaiproxy.v1.ErrorResponse', 'error': {'code': '', 'message': 'proxy: token limit reached. Limit: 50000 / min. Available: 0 / min. Retry after: 3.936334997s. Reset after: 37.625135004s.', 'param': '', 'type': 'proxy_limit_reached', 'critical_data_details': [], 'limit_reached_details': {'type': 'token', 'retry_after': 3.936334997, 'reset_after': 37.625135004}}}, {'@type': 'type.googleapis.com/openaiproxy.v1.StatusCode', 'value': 429}]}}\n"
     ]
    }
   ],
   "source": [
    "corrected_test_lines = get_correction_v3(eval_test[\"str_preds\"], system_prompt=system_prompt, print_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отдельные строки как примеры, учитываем историю, после паддинга + учитываем train\n",
    "\n",
    "print(f\"CER до GPT:    {eval_test[\"cer\"]: .6f}\")\n",
    "print(f\"CER после GPT: {calc_cer_from_list(eval_test[\"str_gt\"], corrected_test_lines) : .6f}\")\n",
    "print(f\"WER до GPT:    {eval_test[\"wer\"]: .6f}\")\n",
    "print(f\"WER после GPT: {calc_wer_from_list(eval_test[\"str_gt\"], corrected_test_lines) : .6f}\")\n",
    "print()\n",
    "\n",
    "for model_line, corrected_line, human_line in zip(eval_test[\"str_preds\"], corrected_test_lines, eval_test[\"str_gt\"], strict=True):\n",
    "    model_cer = editdistance.eval(model_line, human_line) / len(human_line)\n",
    "    gpt_cer = editdistance.eval(corrected_line, human_line) / len(human_line)\n",
    "    print(f\"Model:   {model_line} (cer = {model_cer * 100:.2f}%)\")\n",
    "    print(f\"ChatGPT: {corrected_line} (cer = {gpt_cer * 100:.2f}%)\")\n",
    "    print(f\"Human:   {human_line}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER до GPT:     0.159323\n",
      "CER после GPT:  0.165159\n"
     ]
    }
   ],
   "source": [
    "# отдельные строки как примеры, учитываем историю, после паддинга\n",
    "print(f\"CER до GPT:    {eval_test[\"cer\"]: .6f}\")\n",
    "print(f\"CER после GPT: {calc_cer_from_list(eval_test[\"str_gt\"], corrected_test_lines) : .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER до GPT:     0.506419\n",
      "WER после GPT:  0.425107\n"
     ]
    }
   ],
   "source": [
    "# отдельные строки как примеры, учитываем историю, после паддинга\n",
    "print(f\"WER до GPT:    {eval_test[\"wer\"]: .6f}\")\n",
    "print(f\"WER после GPT: {calc_wer_from_list(eval_test[\"str_gt\"], corrected_test_lines) : .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:   Рябикова (cer = 11.11%)\n",
      "ChatGPT: Рябикова (cer = 11.11%)\n",
      "Human:   Рябчикова\n",
      "\n",
      "Model:   Онъ де жилъ въ раборникахъ, у купца, у кралъ, что-т (cer = 14.00%)\n",
      "ChatGPT: Онъ, де, жилъ въ Рабочникахъ, у купца, укралъ что-то. (cer = 16.00%)\n",
      "Human:   Онъ де жилъ въ работникахъ у купца ; укралъ что-то\n",
      "\n",
      "Model:   и тотъ удорилъ его палькою по головѣ отъ чего у нем (cer = 16.00%)\n",
      "ChatGPT: и тотъ ударилъ его палкою по головѣ, отъ чего у нѣм- (cer = 12.00%)\n",
      "Human:   и тотъ ударилъ его палкою по головѣ, отчаго у него\n",
      "\n",
      "Model:   и сдѣлалась рудето бѣлая горяька. Обратясеь къ Губер- (cer = 9.80%)\n",
      "ChatGPT: и сдѣлалась, вроде, бѣлая горячка. Обратился къ Губер- (cer = 19.61%)\n",
      "Human:   и сдѣлалась будто бѣлая горячка. Обратясь къ губер-\n",
      "\n",
      "Model:   наторуг. В- р росодъ въ, t ріscсe l.1. cлумаюсь. (cer = 58.70%)\n",
      "ChatGPT: Губернатору. Въ разсудъ въ Трясце... Сомневаюсь. (cer = 76.09%)\n",
      "Human:   натору: В – f! Prens-le, pince-le! – Слушаюсь.\n",
      "\n",
      "Model:   Болѣе никакихъ разпоряженій и не было сцѣлано.– Вороемъ (cer = 10.71%)\n",
      "ChatGPT: Болѣе никакихъ разпоряженій и не было сдѣлано. – Вороемъ (cer = 10.71%)\n",
      "Human:   Болѣе никакихъ распоряженій и не было сдѣлано. Впрочемъ,\n",
      "\n",
      "Model:   и часовые возвратижинь на преженія мѣста – ибо (cer = 8.89%)\n",
      "ChatGPT: и часовые возвращены на прежнія мѣста – ибо (cer = 15.56%)\n",
      "Human:   и часовые возвратились на прежніе мѣста – ибо\n",
      "\n",
      "Model:   въ прочимѣномъ слугаѣ и острожные остались бы безъ (cer = 8.16%)\n",
      "ChatGPT: въ противномъ случаѣ и острожные остались бы безъ (cer = 0.00%)\n",
      "Human:   въ противномъ случаѣ и острожные остались бы безъ\n",
      "\n",
      "Model:   всякаго каркува. (cer = 12.50%)\n",
      "ChatGPT: всякаго надзора. (cer = 31.25%)\n",
      "Human:   всякаго караула.\n",
      "\n",
      "Model:   Вечеромъ литалъ піэссу – ядѣ чрезвыайно (cer = 7.32%)\n",
      "ChatGPT: Вечеромъ читалъ піэссу – дѣйствительно чрезвычайно (cer = 31.71%)\n",
      "Human:   Вечеромъ читалъ піэссу – Дядѣ чрезвычайно\n",
      "\n",
      "Model:   понравилась. – беккаеру также. (cer = 10.71%)\n",
      "ChatGPT: понравилась – Беккеру также. (cer = 0.00%)\n",
      "Human:   понравилась – Беккеру также.\n",
      "\n",
      "Model:   10-х. утромъ выѣхалъ въ алексяевское. Почевалъ въ (cer = 10.20%)\n",
      "ChatGPT: 10-е. Утромъ выѣхалъ въ алексяевское. Почивалъ въ (cer = 14.29%)\n",
      "Human:   10-го утромъ выѣхалъ въ Алексеевское. Ночевалъ въ\n",
      "\n",
      "Model:   1856. годъ. Ман. (cer = 21.43%)\n",
      "ChatGPT: 1856. годъ. Мартъ. (cer = 35.71%)\n",
      "Human:   1856 годъ. Май\n",
      "\n",
      "Model:   21 22. 23-е. 24. 25. 26е. Въ Воскресенскомъ. Хлопо- (cer = 3.92%)\n",
      "ChatGPT: 21, 22, 23-е, 24, 25, 26-е. Въ Воскресенскомъ. Хлопо- (cer = 13.73%)\n",
      "Human:   21. 22. 23е. 24. 25. 26е. Въ Воскресенскомъ. Хлопо-\n",
      "\n",
      "Model:   25-го. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ (cer = 6.12%)\n",
      "ChatGPT: 25-го. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳеодоръ изъ (cer = 8.16%)\n",
      "Human:   25е. Пустилъ Заводъ. Вечеромъ пріѣхалъ Ѳедоръ изъ\n",
      "\n",
      "Model:   Степной – тамъ въ сё надышается. Въ Воскресенскомъ (cer = 16.33%)\n",
      "ChatGPT: Степной – тамъ всѣ надышались. Въ Воскресенскомъ (cer = 20.41%)\n",
      "Human:   Степной - тамъ всё подвигается. Въ Воскресенскомъ\n",
      "\n",
      "Model:   съ февраля поступилъ и управляетъ Зерутъ. (cer = 2.44%)\n",
      "ChatGPT: съ февраля поступилъ и управляетъ Зерновъ. (cer = 7.32%)\n",
      "Human:   съ февраля поступилъ и управляетъ Зерунъ.\n",
      "\n",
      "Model:   Ушею идетъ давольно хорошо. Садку сдѣлалъ по (cer = 10.87%)\n",
      "ChatGPT: Дѣло идетъ довольно хорошо. Садку сдѣлалъ по (cer = 10.87%)\n",
      "Human:   У него идетъ довольно хорошо. Садку сдѣлалъ по\n",
      "\n",
      "Model:   правой Сторолѣ парка отве дома къ Ренѣ. Около (cer = 15.91%)\n",
      "ChatGPT: правой сторонѣ парка, отъ двора къ рѣкѣ. Около (cer = 6.82%)\n",
      "Human:   правой сторонѣ парка отъ дома къ рѣкѣ. Около\n",
      "\n",
      "Model:   Дома проводить піэссе. Ставили при мнѣ Шум- (cer = 14.29%)\n",
      "ChatGPT: дома проводитъ піэссы. Ставили при мнѣ Шум- (cer = 11.90%)\n",
      "Human:   дома проводитъ шоссе. Ставили при мнѣ тум-\n",
      "\n",
      "Model:   бы отъдома къ Коноинѣ. (cer = 17.39%)\n",
      "ChatGPT: бы отъ дома къ Кононѣ. (cer = 13.04%)\n",
      "Human:   бы отъ дома къ конюшнѣ.\n",
      "\n",
      "Model:   27-го по утру выѣхалъ въ Москву. Послалъ за (cer = 9.52%)\n",
      "ChatGPT: 27-го по утру выѣхалъ въ Москву. Послалъ за (cer = 9.52%)\n",
      "Human:   27е. По утру выѣхалъ въ Москву. Послалъ за\n",
      "\n",
      "Model:   Ковскимь, который – явился съ предноженіемъ отъ (cer = 8.89%)\n",
      "ChatGPT: Ковскимъ, который явился съ предложеніемъ отъ (cer = 0.00%)\n",
      "Human:   Ковскимъ, который явился съ предложеніемъ отъ\n",
      "\n",
      "Model:   ивана тепелева о тирѣ. Самсонъ отѣдѣжанію (cer = 21.95%)\n",
      "ChatGPT: Ивана Тепелева о тирѣ. Самсонъ отъ задержанію (cer = 24.39%)\n",
      "Human:   Ивана Шепелева о мирѣ. Самсонъ отъѣзжаетъ\n",
      "\n",
      "Model:   съ Ревель. Купилъ ему серебряныхъ вещій на 180 р. (cer = 8.16%)\n",
      "ChatGPT: съ Ревеля. Купилъ ему серебряныхъ вещей на 180 р. (cer = 8.16%)\n",
      "Human:   въ Ревель, купилъ ему серебряныхъ вещей на 180 р.\n",
      "\n",
      "Model:   сереу Сазикова. Отдалъ Кубокъ дня парѣука (cer = 20.45%)\n",
      "ChatGPT: сереу Сазикова. Отдалъ кубокъ для парѣнка. (cer = 18.18%)\n",
      "Human:   сереб. у Садикова. Отдалъ кубокъ для нарѣзки\n",
      "\n",
      "Model:   падпия Самой лову. Надить (cer = 25.93%)\n",
      "ChatGPT: подпись Самойлова. Надпись (cer = 18.52%)\n",
      "Human:   надписи Самойлову. Надпись:\n",
      "\n",
      "Model:   Да снасеніе почибавшихъ – толанину В. В. (cer = 21.05%)\n",
      "ChatGPT: Да спасеніе погибшихъ – Толстину В. В. (cer = 28.95%)\n",
      "Human:   За Спасеніе погибавшихъ – таланту В.В.\n",
      "\n",
      "Model:   Самояло ва презнательные А.В. Сухово.– Ко- (cer = 15.38%)\n",
      "ChatGPT: Самойлова. Признательные А. В. Сухово-Ко- (cer = 7.69%)\n",
      "Human:   Самойлова признательные А.В. Сухово-Ко-\n",
      "\n",
      "Model:   28-е. Сборъ на Выксу. Проицаные съ Самсономъ. (cer = 11.63%)\n",
      "ChatGPT: 28-е. Сборъ на Выксу. Прощанье съ Самсономъ. (cer = 6.98%)\n",
      "Human:   28е. Сборы на Выксу. Прощаніе съ Самсономъ.\n",
      "\n",
      "Model:   продалъ d пудъ патоки но 180 к. сереб. и n.р. ереб. (cer = 27.59%)\n",
      "ChatGPT: продалъ 9 пудъ патоки по 180 к. сереб. и 1 р. сереб. (cer = 22.41%)\n",
      "Human:   Продалъ 1 т. пудов патоки по 1.80 к. сер. и 1 т. р. сереб.\n",
      "\n",
      "Model:   вшесъ Рертеру въ упламу за аппараты Къ сахар (cer = 14.89%)\n",
      "ChatGPT: внёсъ Реттеру въ уплату за аппараты къ сахар- (cer = 10.64%)\n",
      "Human:   внесъ Ферстеру въ уплату за аппараты къ сахаръ-\n",
      "\n",
      "Model:   пошу Заводу. Вечеромъ выкѣхалъ на Выку. (cer = 10.26%)\n",
      "ChatGPT: плавке Заводу. Вечеромъ выѣхалъ на Выксу. (cer = 15.38%)\n",
      "Human:   ному Заводу. Вечеромъ выѣхалъ на Выксу.\n",
      "\n",
      "Model:   29-е. Въ дорогъ. Хвгодно. простудился. Встрѣча въ Вса- (cer = 11.32%)\n",
      "ChatGPT: 29-е. Въ дорогѣ. Холодно. Простудился. Встрѣча въ Выкса- (cer = 7.55%)\n",
      "Human:   29е. Въ дорогѣ. Холодно. Простудился. Встрѣча въ Вла-\n",
      "\n",
      "Model:   дурвіерѣ со какимъ отолченскимъ офицеромъ (cer = 17.50%)\n",
      "ChatGPT: въ дворѣ съ какимъ-то отставнымъ офицеромъ (cer = 42.50%)\n",
      "Human:   димірѣ съ какимъ ополченскимъ офицеромъ.\n",
      "\n",
      "Model:   Понулярность и всеобщал извѣстностъ кречинского (cer = 10.42%)\n",
      "ChatGPT: Популярность и всеобщая извѣстность Кречинскаго (cer = 4.17%)\n",
      "Human:   Популярность и всеобщая извѣстность Кречинского.\n",
      "\n",
      "Model:   Его ужа играли вовсей Россіи. Успѣхъ одинъ вездѣ (cer = 11.76%)\n",
      "ChatGPT: Его уже играли по всей Россіи. Успѣхъ одинъ вездѣ. (cer = 7.84%)\n",
      "Human:   Его уже играютъ во всей Россіи. Успѣхъ одинъ вездѣ.\n",
      "\n",
      "Model:   30-е. въ 11 часовъ утра никемъ неожиданный пріѣ. (cer = 10.87%)\n",
      "ChatGPT: 30-е. Въ 11 часовъ утра, никемъ неожиданный, пріѣхалъ. (cer = 26.09%)\n",
      "Human:   30е въ 11 часовъ утра никѣмъ неожиданный пріе-\n",
      "\n",
      "Model:   халъ на Выксу – отцъ былъ радъ онъ постарѣлъ (cer = 6.52%)\n",
      "ChatGPT: на Выксу – отецъ былъ радъ. Онъ постарѣлъ, (cer = 19.57%)\n",
      "Human:   халъ на Выксу - отецъ былъ радъ, онъ постарѣлъ\n",
      "\n",
      "Model:   нѣсколько потолстѣлъ и въ голось замѣжна перемѣла (cer = 27.27%)\n",
      "ChatGPT: нѣсколько потолстѣлъ, и въ голосѣ замѣтна перемѣна. (cer = 27.27%)\n",
      "Human:   нѣсколько потолстѣлъ и въ голосѣ нѣсколько перемѣнился,\n",
      "\n",
      "Model:   нѣтъ твердости. На Выксѣ сесенра соловая, Честр (cer = 21.28%)\n",
      "ChatGPT: нѣтъ твердости. На Выксѣ сестра больна, Честер (cer = 25.53%)\n",
      "Human:   нѣтъ твердости. На Выксѣ сосѣди Соловые, сестра\n",
      "\n",
      "Model:   Сальясъ, Ина. Тетлевъ и я леховскій. Николай (cer = 22.73%)\n",
      "ChatGPT: Сальясъ, Инна, Тетлевъ и я, Ляховскій. Николай (cer = 29.55%)\n",
      "Human:   Сальясъ, Ник. Шепелевъ и Дмоховскій. Николай\n",
      "\n",
      "Model:   Го0нь 1-е. Рано утромъ съ Соринымъ выѣхалъ на словодь. (cer = 16.98%)\n",
      "ChatGPT: Апрѣль 1-е. Рано утромъ съ Соринымъ выѣхалъ на заводъ. (cer = 20.75%)\n",
      "Human:   Іюнь. 1е. Рано утромъ съ Соринымъ выѣхалъ на Снаведь.\n",
      "\n",
      "Model:   Квгупть, 3-го. Уѣхалъ вълетербургъ. ибо дѣло принаяло дурго (cer = 18.97%)\n",
      "ChatGPT: Калуга, 3-го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной (cer = 12.07%)\n",
      "Human:   Августъ 3го. Уѣхалъ въ Петербургъ, ибо дѣло приняло дурной\n",
      "\n",
      "Model:   оборому въ Мичо л0етъ. Натало тяжелсъ время. Саезыгаколо (cer = 36.21%)\n",
      "ChatGPT: оборотъ въ Мичуринскъ. Началось тяжёлое время. Съезжалось (cer = 39.66%)\n",
      "Human:   оборотъ въ Мин. Юст. Настало тяжелое время. Связь съ Голи-\n",
      "\n",
      "Model:   крѣпокъ. Ходилъ нѣсколько разъ Греть на годку. –и (cer = 12.00%)\n",
      "ChatGPT: крѣпокъ. Ходилъ нѣсколько разъ грѣться на горку. – И (cer = 18.00%)\n",
      "Human:   крѣпокъ. Ходилъ нѣсколько разъ гресть на лодку - и\n",
      "\n",
      "Model:   купался въ шилѣ до паловимы Авгста. (cer = 25.00%)\n",
      "ChatGPT: купался въ Шилѣ до половины Августа. (cer = 16.67%)\n",
      "Human:   купался въ Невѣ съ половины августа.\n",
      "\n",
      "Model:   Cентябрь. Въ Петербургѣ. Подалъ занику М. фов о (cer = 10.20%)\n",
      "ChatGPT: Сентябрь. Въ Петербургѣ. Подалъ записку М. Фов о (cer = 6.12%)\n",
      "Human:   Сентябрь. Въ Петербургѣ. Подалъ записку м. ф-ов о\n",
      "\n",
      "Model:   предирняніи въ 1ож. Россіи. Отравили на Выксу и (cer = 20.83%)\n",
      "ChatGPT: предпріятіи въ Юж. Россіи. Отправили на Выксу и (cer = 10.42%)\n",
      "Human:   предпрiятiи въ Юж. Россiи. Отправился на Выксу и\n",
      "\n",
      "Model:   заключилъ условіе съ кик. Иетя. Пріѣхалъ обратна (cer = 18.75%)\n",
      "ChatGPT: заключилъ условіе съ инж. Иетя. Пріѣхалъ обратно (cer = 20.83%)\n",
      "Human:   заключилъ условие с Ник. Шепел. Прiѣхалъ обратно\n",
      "\n",
      "Model:   въ Петербуркъ. 13-го поябръя. Сововые свня и машавовъ (cer = 31.48%)\n",
      "ChatGPT: въ Петербуркъ 13-го Ноября. Съговоры съ Синя и Машановъ. (cer = 33.33%)\n",
      "Human:   въ Петербургъ 13го ноября. Соловые. Соня и Маменька въ\n",
      "\n",
      "Model:   Петербургъ. Жезнь въ костицѣ Денедола. Постолно (cer = 26.92%)\n",
      "ChatGPT: Петербургъ. Жизнь въ квартирѣ Денедола. Постоянно (cer = 32.69%)\n",
      "Human:   Петербургѣ. Жизнь въ гостиницѣ Демидова. Постановилъ\n",
      "\n",
      "Model:   ходилъ въ Дероту по утрамъ. Окочилъ 2-ой и 3-те акть. (cer = 21.15%)\n",
      "ChatGPT: ходилъ въ Думу по утрамъ. Окончилъ 2-ой и 3-тій актъ. (cer = 21.15%)\n",
      "Human:   ходить къ Депону по утрамъ. Окончилъ 2ой и 3iй актъ.\n",
      "\n",
      "Model:   1дѣло въ гогуд. Совѣтѣ. бръ Торги на встовые (cer = 25.00%)\n",
      "ChatGPT: Дѣло въ Город. Совѣтѣ. Были торги на уставные (cer = 33.33%)\n",
      "Human:   Дѣло въ Госуд. Советѣ. Декабрь Торги на винтовые\n",
      "\n",
      "Model:   Корали. Конывъ и Шульмъ въ Петербургѣ. Декабрь (cer = 17.65%)\n",
      "ChatGPT: Корали. Кошелевъ и Шульмъ въ Петербургѣ. Декабрь (cer = 17.65%)\n",
      "Human:   корабли. Копьевъ и Шульгинъ въ Петербургѣ. Декабрь.\n",
      "\n",
      "Model:   Возвратся въ Москву. (cer = 9.09%)\n",
      "ChatGPT: Возвратился въ Москву. (cer = 0.00%)\n",
      "Human:   Возвратился въ Москву.\n",
      "\n",
      "Model:   1854 годъ. Новый годъ нажелной дорогѣ. Былъ въ оскре- (cer = 8.93%)\n",
      "ChatGPT: 1854 годъ. Новый годъ на желѣзной дорогѣ. Былъ въ Оскре- (cer = 5.36%)\n",
      "Human:   1854 годъ. Новый годъ на желѣзной дорогѣ. Былъ в Воскре-\n",
      "\n",
      "Model:   снискомъ. 15 числа выѣхалъ на Выку. Амнtt Гол. (cer = 17.02%)\n",
      "ChatGPT: снѣжкомъ. 15 числа выѣхалъ на Выксу. Аmnt Гол. (cer = 19.15%)\n",
      "Human:   сенскомъ. 15 числа выѣхал на Выксу. Anette Гол.\n",
      "\n",
      "Model:   Піэсса, читалась въ успѣхомъ. Въ феврагѣ (cer = 15.38%)\n",
      "ChatGPT: Піэсса читалась съ успѣхомъ. Въ феврале (cer = 10.26%)\n",
      "Human:   Пьесса читалась съ успехомъ. Въ февралѣ\n",
      "\n",
      "Model:   должъ былъ ѣхать въ Москву по полоду начавшаеттъ, (cer = 19.23%)\n",
      "ChatGPT: долженъ былъ ѣхать въ Москву по поводу начавшагося, (cer = 5.77%)\n",
      "Human:   долженъ былъ выѣхать въ Москву по поводу начавшагося\n",
      "\n",
      "Model:   слѣзмвія. Ѣяздилъ на нѣсколько дей въ Петербургъ. (cer = 14.29%)\n",
      "ChatGPT: слѣсарства. Ѣздилъ на нѣсколько дней въ Петербургъ. (cer = 12.24%)\n",
      "Human:   слѣдствiя. Ѣздилъ на нѣсколько дней в Петербургъ.\n",
      "\n",
      "Model:   Иатупалъ охогиминыихъ вещю чтобы охотится. (cer = 29.55%)\n",
      "ChatGPT: Закупалъ охотничьихъ вещей, чтобы охотиться. (cer = 6.82%)\n",
      "Human:   Покупалъ охотничьихѣ вещей, чтобы охотиться.\n",
      "\n",
      "Model:   2-го Маретъ на тервой недѣли воротилси въ Москву. (cer = 19.15%)\n",
      "ChatGPT: 2-го Марта, на первой недѣлѣ, воротился въ Москву. (cer = 12.77%)\n",
      "Human:   1гo марта на первой недѣлѣ воротился въ Москву.\n",
      "\n",
      "Model:   для пріема Дамъ. Онъ пріѣхали поздно. Обѣдали въ 6-мъ часу – было (cer = 4.69%)\n",
      "ChatGPT: для пріема дамъ. Они пріѣхали поздно. Обѣдали въ 6-мъ часу – было (cer = 3.12%)\n",
      "Human:   для пріема дамъ. Онѣ пріѣхали поздно. Обѣдали въ 6мъ часу – было\n",
      "\n",
      "Model:   довольно весело. – я очно вечено игралъ въ карты. (cer = 13.46%)\n",
      "ChatGPT: довольно весело. – Я почти весь вечеръ игралъ въ карты. (cer = 21.15%)\n",
      "Human:   довольно весело. – Я очень весело игралъ въ карты. –\n",
      "\n",
      "Model:   нѣтъ я отправилъ семна съ. Въ Тулу Запродать будущаго сахара. (cer = 12.70%)\n",
      "ChatGPT: Нѣтъ, я отправилъ Семёна въ Тулу запродать будущаго сахара. (cer = 12.70%)\n",
      "Human:   нѣтъ. Я отправилъ Семена Ив. въ Тулу запродать будущаго сахара.\n",
      "\n",
      "Model:   28е. РаВсталъ рано сполярничалъ. Распимывалъ и отправилъ Выю- (cer = 14.75%)\n",
      "ChatGPT: 28-е. Всталъ рано, сполярничалъ. Расписывалъ и отправилъ въ Выксу. (cer = 21.31%)\n",
      "Human:   28е. Всталъ рано. Столярничалъ. Разсчитывалъ и отправилъ Вык-\n",
      "\n",
      "Model:   сумскихъ 18 человѣхъ. На обратныхъ пододавъ затробовалъ изъ Москвы (cer = 7.46%)\n",
      "ChatGPT: Сумскихъ 18 человѣкъ. На обратныхъ поездахъ затребовалъ изъ Москвы. (cer = 8.96%)\n",
      "Human:   сунскихъ 18 человѣкъ. На обратныхъ подводахъ затребовалъ изъ Москвы\n",
      "\n",
      "Model:   Либили, картинъ, брозу. Естя пзѣ неибудь буду жить ъ оссіи – такъ (cer = 21.74%)\n",
      "ChatGPT: Ливреи, картины, бронзу. Если гдѣ-нибудь буду жить въ Россіи – такъ (cer = 11.59%)\n",
      "Human:   мебель, картины, бронзу. Если я гдѣ-нибудь буду жить въ Россіи – такъ\n",
      "\n",
      "Model:   это здѣсь – въ кобыликѣ. – (cer = 16.00%)\n",
      "ChatGPT: это здѣсь – въ Кобыликѣ. – (cer = 12.00%)\n",
      "Human:   это здѣсь – въ Кобылинкѣ.\n",
      "\n",
      "Model:   Замѣчательный раскаръ о помѣщикѣ Малиновскомъ убинномъ его (cer = 6.90%)\n",
      "ChatGPT: Замѣчательный разсказъ о помѣщикѣ Малиновскомъ, убитомъ его (cer = 1.72%)\n",
      "Human:   Замѣчательный расказъ о помѣщикѣ Малиновскомъ, убитомъ его\n",
      "\n",
      "Model:   крестьянами. Какъ замѣшно это было Сильной странно (cer = 13.73%)\n",
      "ChatGPT: крестьянами. Какъ замѣшано это было – сильно странно. (cer = 19.61%)\n",
      "Human:   крестьянами. Какъ замѣтно это была сильная, страшно\n",
      "\n",
      "Model:   онъ довста Крестьямъ до большаго благю состоянія и богат- (cer = 14.29%)\n",
      "ChatGPT: онъ довёлъ крестьянъ до большого благосостоянія и богат- (cer = 1.79%)\n",
      "Human:   онъ довелъ крестьянъ до большого благосостоянія и богат-\n",
      "\n",
      "Model:   ства, получилъ имѣніе разоренное и кресетьясъ протившотя – (cer = 15.79%)\n",
      "ChatGPT: ства, получилъ имѣніе разоренное, и крестьяне восстали противъ него – (cer = 36.84%)\n",
      "Human:   ства, получивъ имѣніе разоренное и крестьянъ прожившихся.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_line, corrected_line, human_line in zip(eval_test[\"str_preds\"], corrected_test_lines, eval_test[\"str_gt\"], strict=True):\n",
    "    model_cer = editdistance.eval(model_line, human_line) / len(human_line)\n",
    "    gpt_cer = editdistance.eval(corrected_line, human_line) / len(human_line)\n",
    "    print(f\"Model:   {model_line} (cer = {model_cer * 100:.2f}%)\")\n",
    "    print(f\"ChatGPT: {corrected_line} (cer = {gpt_cer * 100:.2f}%)\")\n",
    "    print(f\"Human:   {human_line}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
